{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2O1Fzw7fbTP"
      },
      "source": [
        "# Packages and ngspice setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HW4XA7LfZ1d",
        "outputId": "a00f7f70-815f-4541-f0c4-7e050475b44a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!sudo apt-get install ngspice libngspice0\n",
        "\n",
        "# Create a symbolic link for libngspice.so if it doesn't exist\n",
        "# This is often needed because PySpice looks for libngspice.so (without the version number)\n",
        "!if [ ! -f /usr/lib/x86_64-linux-gnu/libngspice.so ]; then \\\n",
        "    sudo ln -s /usr/lib/x86_64-linux-gnu/libngspice.so.0 /usr/lib/x86_64-linux-gnu/libngspice.so; \\\n",
        "    echo \"Created symlink /usr/lib/x86_64-linux-gnu/libngspice.so\"; \\\n",
        "fi\n",
        "\n",
        "# Set the environment variable for PySpice to find ngspice\n",
        "import os\n",
        "os.environ['PYSPICE_NGSPICE_PATH'] = '/usr/lib/x86_64-linux-gnu/libngspice.so.0'\n",
        "\n",
        "!pip install PySpice\n",
        "\n",
        "# Diagnostic: Find the actual path of libngspice.so\n",
        "# Please share the output of this command after execution.\n",
        "!dpkg -L ngspice\n",
        "!dpkg -L libngspice0\n",
        "\n",
        "# Further Diagnostics: Check file existence and dependencies\n",
        "!ls -l /usr/lib/x86_64-linux-gnu/libngspice.so\n",
        "!ldd /usr/lib/x86_64-linux-gnu/libngspice.so\n",
        "\n",
        "import PySpice.Logging.Logging as Logging\n",
        "import logging # Import the standard logging module\n",
        "from PySpice.Spice.Netlist import Circuit\n",
        "from PySpice.Unit import *\n",
        "from PySpice.Spice.Parser import SpiceParser\n",
        "import re\n",
        "import torch\n",
        "import scipy.signal as signal\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import concurrent.futures\n",
        "import multiprocessing\n",
        "import random\n",
        "import glob\n",
        "\n",
        "# Suppress specific PySpice warnings\n",
        "logger = Logging.setup_logging()\n",
        "logger.setLevel(logging.ERROR) # Use logging.ERROR instead of Logging.ERROR\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5UcA0tSbqpj"
      },
      "source": [
        "# Netlist Processor (SPICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js_OJDXsj5Y_"
      },
      "outputs": [],
      "source": [
        "class NetlistProcessor:\n",
        "    \"\"\"\n",
        "    Motor de an√°lisis de Netlists para el Kaspix Omni-Pipeline.\n",
        "    Encargado de parsear, validar y extraer la configuraci√≥n param√©trica\n",
        "    de circuitos SPICE est√°ndar.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, file_path):\n",
        "        self.file_path = file_path\n",
        "        self.content = \"\"\n",
        "        self.params_raw = {}      # Diccionario original (texto, ej: '10k')\n",
        "        self.params_float = {}    # Diccionario num√©rico (float, ej: 10000.0)\n",
        "        self.io_config = {        # Metadatos de entrada/salida\n",
        "            \"input_source\": None,\n",
        "            \"output_node\": None,\n",
        "            \"ground_check\": False\n",
        "        }\n",
        "        self.is_parsed = False\n",
        "\n",
        "        # Carga inmediata\n",
        "        self._load_file()\n",
        "\n",
        "    def _load_file(self):\n",
        "        if not os.path.exists(self.file_path):\n",
        "            raise FileNotFoundError(f\"[Kaspix Error] No se encuentra el archivo: {self.file_path}\")\n",
        "\n",
        "        with open(self.file_path, 'r', encoding='utf-8') as f:\n",
        "            self.content = f.read()\n",
        "\n",
        "    def _spice_to_float(self, value_str):\n",
        "        \"\"\"\n",
        "        Convierte sufijos de ingenier√≠a SPICE a float de Python.\n",
        "        Soporta: T, G, Meg, k, m, u, n, p, f\n",
        "        \"\"\"\n",
        "        value_str = value_str.lower().strip('{} ') # Limpiar llaves y espacios\n",
        "\n",
        "        # Mapa de multiplicadores SPICE\n",
        "        suffixes = {\n",
        "            't': 1e12, 'g': 1e9, 'meg': 1e6, 'k': 1e3,\n",
        "            'mil': 25.4e-6, 'm': 1e-3, 'u': 1e-6,\n",
        "            'n': 1e-9, 'p': 1e-12, 'f': 1e-15\n",
        "        }\n",
        "\n",
        "        # Regex para separar n√∫mero y sufijo\n",
        "        # Busca un n√∫mero (int o float) seguido opcionalmente de letras\n",
        "        match = re.match(r'^([\\d\\.\\-\\+]+)([a-z]*)$', value_str)\n",
        "\n",
        "        if not match:\n",
        "            try:\n",
        "                return float(value_str) # Intento directo\n",
        "            except ValueError:\n",
        "                return None # No es un n√∫mero parseable (ej: una f√≥rmula compleja)\n",
        "\n",
        "        number, suffix = match.groups()\n",
        "        multiplier = 1.0\n",
        "\n",
        "        if suffix:\n",
        "            # SPICE es 'greedy' con los sufijos, 'meg' es especial\n",
        "            if suffix.startswith('meg'):\n",
        "                multiplier = suffixes['meg']\n",
        "            elif suffix[0] in suffixes:\n",
        "                multiplier = suffixes[suffix[0]]\n",
        "\n",
        "        return float(number) * multiplier\n",
        "\n",
        "    def analyze(self):\n",
        "        \"\"\"\n",
        "        Ejecuta el an√°lisis l√©xico del netlist.\n",
        "        \"\"\"\n",
        "        lines = self.content.splitlines()\n",
        "\n",
        "        # Regex Compilados\n",
        "        re_param = re.compile(r'\\.param\\s+(\\w+)\\s*=\\s*(\\{?[\\w\\.\\-\\+]+\\}?)', re.IGNORECASE)\n",
        "        re_source = re.compile(r'^\\s*([vV]\\w+)\\s+(\\w+)\\s+(\\w+)', re.IGNORECASE)\n",
        "        re_save = re.compile(r'\\.(?:save|print)\\s+(?:v|tran)\\s*\\((.+?)\\)', re.IGNORECASE)\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line or line.startswith('*'): continue\n",
        "\n",
        "            # 1. Detectar Par√°metros (.param)\n",
        "            pm = re_param.search(line)\n",
        "            if pm:\n",
        "                name, val_str = pm.groups()\n",
        "                # Guardar raw\n",
        "                self.params_raw[name] = val_str\n",
        "                # Convertir a float\n",
        "                val_float = self._spice_to_float(val_str)\n",
        "                if val_float is not None:\n",
        "                    self.params_float[name] = val_float\n",
        "\n",
        "            # 2. Detectar Inputs (Heur√≠stica: Nombre contiene 'in' o 'src')\n",
        "            sm = re_source.match(line)\n",
        "            if sm:\n",
        "                s_name, n_pos, n_neg = sm.groups()\n",
        "                # Priorizamos fuentes que parezcan de se√±al\n",
        "                if 'in' in s_name.lower() or 'src' in s_name.lower() or 'sig' in s_name.lower():\n",
        "                    self.io_config[\"input_source\"] = s_name\n",
        "\n",
        "            # 3. Detectar Ground\n",
        "            if ' 0 ' in line or line.endswith(' 0'):\n",
        "                self.io_config[\"ground_check\"] = True\n",
        "\n",
        "            # 4. Detectar Output (.save)\n",
        "            svm = re_save.search(line)\n",
        "            if svm:\n",
        "                # Extraer contenido dentro de par√©ntesis\n",
        "                nodes = svm.group(1).replace(')', '').replace('(', '').split()\n",
        "                if nodes:\n",
        "                    self.io_config[\"output_node\"] = nodes[0] # Tomamos el primero como principal\n",
        "\n",
        "        # Fallback para Output si no hay .save\n",
        "        if not self.io_config[\"output_node\"]:\n",
        "             if re.search(r'\\b(out|output|salida)\\b', self.content, re.IGNORECASE):\n",
        "                 self.io_config[\"output_node\"] = \"out (Inferred)\"\n",
        "             else:\n",
        "                 self.io_config[\"output_node\"] = \"UNKNOWN (Define .save V(node))\"\n",
        "\n",
        "        self.is_parsed = True\n",
        "        return self.get_summary()\n",
        "\n",
        "    def get_summary(self):\n",
        "        if not self.is_parsed: return \"No analizado.\"\n",
        "        return {\n",
        "            \"file_path\": self.file_path,\n",
        "            \"valid_spice\": self.io_config[\"ground_check\"],\n",
        "            \"knobs_detected\": list(self.params_float.keys()),\n",
        "            \"knobs_values\": self.params_float,\n",
        "            \"input_source\": self.io_config[\"input_source\"],\n",
        "            \"output_target\": self.io_config[\"output_node\"]\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWnEOqNEbqpr"
      },
      "source": [
        "# Dataset Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u3er8LDqZuW"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# 0. FUNCIONES AUXILIARES - REPRODUCIBILIDAD\n",
        "# ============================================================================\n",
        "def set_global_seed(seed=42):\n",
        "    \"\"\"\n",
        "    Establece semillas aleatorias para reproducibilidad total.\n",
        "\n",
        "    Args:\n",
        "        seed: Semilla (int)\n",
        "    \"\"\"\n",
        "    import random\n",
        "    import numpy as np\n",
        "    import torch\n",
        "\n",
        "    # Python random\n",
        "    random.seed(seed)\n",
        "\n",
        "    # NumPy random\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # PyTorch random\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # Si usas CUDA (GPU)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # Para multi-GPU\n",
        "\n",
        "        # Configuraci√≥n para reproducibilidad CUDA (m√°s lento pero determinista)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    print(f\"‚úÖ Kaspix Seed Locked: {seed}\")\n",
        "\n",
        "# ============================================================\n",
        "# 1. KASPIX SIGNAL FACTORY (Con Din√°mica de Amplitud)\n",
        "# ============================================================\n",
        "class KaspixSignalFactory:\n",
        "    def __init__(self, fs, duration_sec):\n",
        "        self.fs = fs\n",
        "        self.duration = duration_sec\n",
        "        self.n_samples = int(fs * duration_sec)\n",
        "        self.time_axis = np.linspace(0, duration_sec, self.n_samples)\n",
        "\n",
        "    def _apply_dynamic_gain(self, y):\n",
        "        \"\"\"\n",
        "        Simula la variaci√≥n de volumen de entrada (Din√°mica).\n",
        "        \"\"\"\n",
        "        target_peak = np.exp(np.random.uniform(np.log(0.05), np.log(1.5)))\n",
        "        max_val = np.max(np.abs(y))\n",
        "        if max_val > 1e-9:\n",
        "            return (y / max_val) * target_peak\n",
        "        return y\n",
        "\n",
        "    def _apply_input_noise(self, signal_in):\n",
        "        \"\"\"\n",
        "        [NUEVO] Inyecta un 'Piso de Ruido' realista.\n",
        "        Simula interferencia el√©ctrica, t√©rmica o de cables.\n",
        "        \"\"\"\n",
        "        # 1. Decidir si esta muestra tendr√° ruido (90% de las veces s√≠)\n",
        "        if np.random.rand() > 0.9:\n",
        "            return signal_in\n",
        "\n",
        "        # 2. Generar Ruido Base (Blanco)\n",
        "        noise = np.random.randn(len(signal_in))\n",
        "\n",
        "        # 3. Determinar nivel de ruido (SNR)\n",
        "        # Un 'Noise Floor' t√≠pico en audio va de -60dB (bueno) a -30dB (malo/vintage)\n",
        "        # Calculamos la amplitud del ruido basada en una referencia fija (no relativa a la se√±al)\n",
        "        # Esto simula que el ruido es constante independientemente de si tocas fuerte o suave.\n",
        "        noise_level_db = np.random.uniform(-70, -30)\n",
        "        noise_amplitude = 10 ** (noise_level_db / 20)\n",
        "\n",
        "        # 4. Mezclar\n",
        "        noisy_signal = signal_in + (noise * noise_amplitude)\n",
        "\n",
        "        # Opcional: Recortar picos si se pasa de +/- 1.5V (Safety Clip)\n",
        "        return np.clip(noisy_signal, -1.5, 1.5)\n",
        "\n",
        "    # --- Generadores Primitivos ---\n",
        "    def _pink_noise(self):\n",
        "        uneven = self.n_samples % 2\n",
        "        X = np.random.randn(self.n_samples // 2 + 1 + uneven) + 1j * np.random.randn(self.n_samples // 2 + 1 + uneven)\n",
        "        S = np.sqrt(np.arange(len(X)) + 1.)\n",
        "        y = (np.fft.irfft(X / S)).real\n",
        "        if uneven: y = y[:-1]\n",
        "        # ORDEN F√çSICO: Se√±al -> Ganancia -> Ruido de Cable\n",
        "        y = self._apply_dynamic_gain(y)\n",
        "        return self._apply_input_noise(y)\n",
        "\n",
        "    def _chirp_log(self):\n",
        "        f_start = 20\n",
        "        f_end = np.random.uniform(self.fs/4, self.fs/2 * 0.9)\n",
        "        y = signal.chirp(self.time_axis, f0=f_start, f1=f_end, t1=self.duration, method='logarithmic')\n",
        "        y = self._apply_dynamic_gain(y)\n",
        "        return self._apply_input_noise(y)\n",
        "\n",
        "    def _step_sequence(self):\n",
        "        num_steps = np.random.randint(3, 12)\n",
        "        y = np.zeros_like(self.time_axis)\n",
        "        indices = np.sort(np.random.choice(np.arange(self.n_samples), num_steps, replace=False))\n",
        "        levels = np.random.uniform(-0.8, 0.8, num_steps)\n",
        "        current_idx = 0\n",
        "        for i, idx in enumerate(indices):\n",
        "            y[current_idx:idx] = levels[i-1] if i > 0 else 0\n",
        "            current_idx = idx\n",
        "        y[current_idx:] = levels[-1]\n",
        "        # Los steps ya tienen amplitud propia, solo a√±adimos ruido\n",
        "        return self._apply_input_noise(y)\n",
        "\n",
        "    def _multitone(self):\n",
        "        num_tones = np.random.randint(3, 15)\n",
        "        y = np.zeros_like(self.time_axis)\n",
        "        for _ in range(num_tones):\n",
        "            freq = np.random.uniform(20, self.fs/3)\n",
        "            phase = np.random.uniform(0, 2*np.pi)\n",
        "            y += np.sin(2 * np.pi * freq * self.time_axis + phase)\n",
        "        y = self._apply_dynamic_gain(y)\n",
        "        return self._apply_input_noise(y)\n",
        "\n",
        "    def _impulse_train(self):\n",
        "        y = np.zeros_like(self.time_axis)\n",
        "        num_impulses = np.random.randint(1, 5)\n",
        "        indices = np.random.randint(0, self.n_samples, num_impulses)\n",
        "        y[indices] = 1.0\n",
        "        # Impulsos limpios suelen ser mejores para analisis, pero ruido leve no da√±a\n",
        "        return self._apply_input_noise(y)\n",
        "\n",
        "    def get_signal(self, recipe):\n",
        "        keys = list(recipe.keys())\n",
        "        probs = np.array(list(recipe.values()))\n",
        "        probs /= probs.sum()\n",
        "        choice = np.random.choice(keys, p=probs)\n",
        "\n",
        "        sig = None\n",
        "        name = \"Unknown\"\n",
        "\n",
        "        if choice == 'chirp':\n",
        "            sig, name = self._chirp_log(), \"Chirp Log\"\n",
        "        elif choice == 'pink_noise':\n",
        "            sig, name = self._pink_noise(), \"Pink Noise\"\n",
        "        elif choice == 'step_sequence':\n",
        "            sig, name = self._step_sequence(), \"Step Seq\"\n",
        "        elif choice == 'multitone':\n",
        "            sig, name = self._multitone(), \"Multitone\"\n",
        "        elif choice == 'impulse':\n",
        "            sig, name = self._impulse_train(), \"Impulse\"\n",
        "        elif choice == 'sine':\n",
        "            f = np.random.uniform(20, 1000)\n",
        "            raw = np.sin(2*np.pi*f*self.time_axis)\n",
        "            sig, name = self._apply_input_noise(self._apply_dynamic_gain(raw)), f\"Sine {int(f)}Hz\"\n",
        "        elif choice == 'silence_decay':\n",
        "             raw = np.zeros_like(self.time_axis)\n",
        "             raw[:int(self.n_samples*0.1)] = np.random.randn(int(self.n_samples*0.1))\n",
        "             # El silencio DEBE tener ruido de fondo para ser realista\n",
        "             sig, name = self._apply_input_noise(self._apply_dynamic_gain(raw)), \"Silence Decay\"\n",
        "        else:\n",
        "            sig, name = self._pink_noise(), \"Default (Pink)\"\n",
        "\n",
        "        return sig, name\n",
        "\n",
        "# ============================================================\n",
        "# 2. WORKER SIMULATOR (Con soporte para Dummy Knob)\n",
        "# ============================================================\n",
        "def _simulation_worker(task_payload):\n",
        "    try:\n",
        "        file_path = task_payload['file_path']\n",
        "        input_source = task_payload['input_source']\n",
        "        output_target = task_payload['output_target']\n",
        "        fs = task_payload['fs']\n",
        "        duration = task_payload['duration']\n",
        "        input_signal = task_payload['input_signal']\n",
        "        knob_config = task_payload['knob_config']\n",
        "        task_id = task_payload['id']\n",
        "\n",
        "        # 1. Construir el circuito\n",
        "        parser = SpiceParser(path=file_path)\n",
        "        circuit = parser.build_circuit()\n",
        "\n",
        "        # 2. Inyecci√≥n de Fuente PWL (Se√±al de Audio)\n",
        "        actual_source_name = None\n",
        "        for element in circuit.element_names:\n",
        "            if element.upper() == input_source.upper():\n",
        "                actual_source_name = element\n",
        "                break\n",
        "\n",
        "        if actual_source_name:\n",
        "            original_source = circuit[actual_source_name]\n",
        "            n_pos, n_neg = original_source.nodes[0], original_source.nodes[1]\n",
        "            circuit._elements.pop(actual_source_name)\n",
        "            \n",
        "            time_axis = np.linspace(0, duration, len(input_signal))\n",
        "            input_data = list(zip(time_axis.astype(float), input_signal.astype(float)))\n",
        "            circuit.PieceWiseLinearVoltageSource('Input_UES', n_pos, n_neg, values=input_data)\n",
        "        else:\n",
        "            return {\"status\": \"error\", \"msg\": f\"Fuente {input_source} no hallada\", \"id\": task_id}\n",
        "\n",
        "        # 3. APLICAR KNOBS (Inyecci√≥n Directa en Componentes)\n",
        "        # Esta l√≥gica busca el componente (R1, C1, etc) y cambia su valor f√≠sico\n",
        "        # Si no lo encuentra, lo intenta como par√°metro global\n",
        "        for name, val in knob_config.items():\n",
        "            if name == 'dummy_param': continue\n",
        "            \n",
        "            if name in circuit.element_names:\n",
        "                obj = circuit[name]\n",
        "                val_f = float(val)\n",
        "                # Mapeo din√°mico de atributos seg√∫n el tipo de componente\n",
        "                if hasattr(obj, 'resistance'): obj.resistance = val_f\n",
        "                elif hasattr(obj, 'capacitance'): obj.capacitance = val_f\n",
        "                elif hasattr(obj, 'inductance'): obj.inductance = val_f # <-- IMPORTANTE PARA WAH\n",
        "                elif hasattr(obj, 'dc_value'): obj.dc_value = val_f      # Para fuentes V e I\n",
        "                elif hasattr(obj, 'voltage_gain'): obj.voltage_gain = val_f # Para OpAmps/E\n",
        "            else:\n",
        "                # Fallback a par√°metro de sistema (.param)\n",
        "                circuit.parameter(name, val)\n",
        "\n",
        "        # 4. SIMULACI√ìN (Con l√≠mites de seguridad)\n",
        "        # Usamos un step_time ligeramente mayor si es necesario para ayudar a la convergencia\n",
        "        simulator = circuit.simulator(temperature=25, nominal_temperature=25)\n",
        "        \n",
        "        # [MOD] A√±adimos un bloque try espec√≠fico para la simulaci√≥n\n",
        "        try:\n",
        "            analysis = simulator.transient(step_time=1.0/fs, end_time=duration)\n",
        "        except Exception as e:\n",
        "            return {\"status\": \"error\", \"msg\": f\"NGSpice Crash: {str(e)}\", \"id\": task_id}\n",
        "\n",
        "        # 5. EXTRACCI√ìN Y LIMPIEZA\n",
        "        output_signal = None\n",
        "        # Normalizar nombres de nodos para la b√∫squeda\n",
        "        target_clean = output_target.upper().replace('V(', '').replace(')', '')\n",
        "        \n",
        "        for node_name in analysis.nodes:\n",
        "            if str(node_name).upper() == target_clean:\n",
        "                output_signal = np.array(analysis.nodes[node_name])\n",
        "                break\n",
        "\n",
        "        if output_signal is None:\n",
        "            return {\"status\": \"error\", \"msg\": f\"Nodo {output_target} no encontrado\", \"id\": task_id}\n",
        "\n",
        "        # 6. FILTRO DE ESTABILIDAD (Anti-Explosi√≥n)\n",
        "        # Si la se√±al tiene NaNs o voltajes absurdos (ej. > 100V en un pedal de 9V), descartamos\n",
        "        if np.isnan(output_signal).any() or np.max(np.abs(output_signal)) > 100:\n",
        "            return {\"status\": \"error\", \"msg\": \"Inestabilidad num√©rica detectada (Overflow)\", \"id\": task_id}\n",
        "\n",
        "        # Resamplear si el simulador cambi√≥ el paso de tiempo\n",
        "        if len(output_signal) != len(time_axis):\n",
        "            output_signal = np.interp(time_axis, np.array(analysis.time), output_signal)\n",
        "\n",
        "        return {\n",
        "            \"status\": \"ok\",\n",
        "            \"id\": task_id,\n",
        "            \"y\": output_signal.astype(np.float32),\n",
        "            \"x_meta\": {\n",
        "                \"knobs\": np.array(list(knob_config.values()), dtype=np.float32),\n",
        "                \"knob_names\": list(knob_config.keys())\n",
        "            }\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"msg\": f\"Worker Fail: {str(e)}\", \"id\": task_payload.get('id', -1)}\n",
        "\n",
        "# ============================================================\n",
        "# 3. KASPIX GENERATOR (Con inyecci√≥n de Dummy Knob)\n",
        "# ============================================================\n",
        "class KaspixParallelGenerator:\n",
        "    def __init__(self, processor_result, fs=48000, duration_sec=0.2, recipe=None, seed=42):\n",
        "        self.meta = processor_result\n",
        "        self.fs = fs\n",
        "        self.duration = duration_sec\n",
        "        self.seed = seed\n",
        "        self.factory = KaspixSignalFactory(fs, duration_sec)\n",
        "        self.time_axis = self.factory.time_axis\n",
        "        self.recipe = recipe if recipe else {\"chirp\": 1.0}\n",
        "\n",
        "        if not self.meta['valid_spice']:\n",
        "            raise ValueError(\"[Kaspix] Netlist inv√°lido.\")\n",
        "\n",
        "        self.max_workers = multiprocessing.cpu_count()\n",
        "        print(f\"‚ö° Kaspix Parallel Engine V6 (Dynamic Gain + Dummy Fix): {self.max_workers} n√∫cleos | Seed: {self.seed}\")\n",
        "\n",
        "    def _sample_knobs(self, variation_pct=0.8):\n",
        "        nominal = self.meta['knobs_values']\n",
        "\n",
        "        # [MEJORA #3] Si no hay knobs detectados, inyectar uno falso\n",
        "        if not nominal:\n",
        "            # Retornamos un valor fijo (ej. 1.0) para mantener la estructura FiLM\n",
        "            return {'dummy_param': 1.0}\n",
        "\n",
        "        sampled = {}\n",
        "        for name, val in nominal.items():\n",
        "            delta = val * variation_pct\n",
        "            new_val = np.random.uniform(val - delta, val + delta)\n",
        "            if new_val <= 0: new_val = val * 0.01\n",
        "            sampled[name] = new_val\n",
        "        return sampled\n",
        "\n",
        "    def build_dataset(self, n_samples=100, save_path=\"kaspix_dataset.pt\"):\n",
        "        set_global_seed(self.seed)\n",
        "        print(f\"--- Preparando {n_samples} tareas deterministas ---\")\n",
        "\n",
        "        tasks = []\n",
        "        pre_generated_signals = {}\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            sig_in, sig_type = self.factory.get_signal(self.recipe)\n",
        "            knobs = self._sample_knobs()\n",
        "\n",
        "            pre_generated_signals[i] = {\n",
        "                \"audio_in\": sig_in.astype(np.float32),\n",
        "                \"signal_type\": sig_type\n",
        "            }\n",
        "\n",
        "            task = {\n",
        "                \"id\": i,\n",
        "                \"file_path\": self.meta['file_path'],\n",
        "                \"input_source\": self.meta['input_source'],\n",
        "                \"output_target\": self.meta['output_target'],\n",
        "                \"fs\": self.fs,\n",
        "                \"duration\": self.duration,\n",
        "                \"input_signal\": sig_in,\n",
        "                \"knob_config\": knobs\n",
        "            }\n",
        "            tasks.append(task)\n",
        "\n",
        "        print(f\"üöÄ Procesando...\")\n",
        "        results_unsorted = []\n",
        "        with concurrent.futures.ProcessPoolExecutor(max_workers=self.max_workers) as executor:\n",
        "            results_unsorted = list(tqdm(executor.map(_simulation_worker, tasks), total=n_samples))\n",
        "\n",
        "        print(\"üì¶ Ordenando y verificando consistencia...\")\n",
        "        results_sorted = sorted(results_unsorted, key=lambda x: x['id'])\n",
        "\n",
        "        dataset_x = []\n",
        "        dataset_y = []\n",
        "        success_count = 0\n",
        "\n",
        "        for res in results_sorted:\n",
        "            idx = res['id']\n",
        "            if res['status'] == 'ok':\n",
        "                input_meta = pre_generated_signals[idx]\n",
        "                worker_meta = res['x_meta']\n",
        "                x_entry = {\n",
        "                    \"audio_in\": input_meta['audio_in'],\n",
        "                    \"signal_type\": input_meta['signal_type'],\n",
        "                    \"knobs\": worker_meta['knobs'],\n",
        "                    \"knob_names\": worker_meta['knob_names']\n",
        "                }\n",
        "                dataset_x.append(x_entry)\n",
        "                dataset_y.append(res['y'])\n",
        "                success_count += 1\n",
        "            else:\n",
        "                if success_count == 0:\n",
        "                    print(f\"‚ùå Error en muestra {idx}: {res['msg']}\")\n",
        "\n",
        "        if success_count == 0:\n",
        "            print(\"‚ùå FALLO TOTAL.\")\n",
        "            return [], []\n",
        "\n",
        "        print(f\"üíæ Guardando {success_count}/{n_samples} muestras en {save_path}...\")\n",
        "        torch.save({\n",
        "            \"x\": dataset_x,\n",
        "            \"y\": dataset_y,\n",
        "            \"fs\": self.fs,\n",
        "            \"meta\": self.meta,\n",
        "            \"recipe\": self.recipe,\n",
        "            \"seed\": self.seed\n",
        "        }, save_path)\n",
        "\n",
        "        return dataset_x, dataset_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqlkzoiIbqpy"
      },
      "source": [
        "# Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT7AaM17rXpG",
        "outputId": "769cc4e1-1074-4398-d815-897044887dde"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# BLOQUE PRINCIPAL DE EJECUCI√ìN (KASPIX OMNI-PIPELINE V4.2)\n",
        "# ============================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. CONFIGURACI√ìN GLOBAL Y RUTAS\n",
        "    # ------------------------------------------------------------\n",
        "    CIRCUITS_DIR = \"circuits\"\n",
        "    DATA_DIR = \"datasets\"\n",
        "    OUTPUT_DATASET = \"kaspix_full_dataset.pt\"\n",
        "\n",
        "    os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "    N_SAMPLES_PER_NETLIST = 50\n",
        "    SAMPLE_RATE = 48000\n",
        "    DURATION = 0.04\n",
        "\n",
        "    RECIPE_MIX = {\n",
        "        \"chirp\": 0.25, \"pink_noise\": 0.20, \"multitone\": 0.15,\n",
        "        \"step_sequence\": 0.20, \"sine\": 0.10, \"impulse\": 0.05,\n",
        "        \"silence_decay\": 0.05\n",
        "    }\n",
        "\n",
        "    netlist_files = sorted(glob.glob(os.path.join(CIRCUITS_DIR, \"*.cir\")))\n",
        "\n",
        "    if not netlist_files:\n",
        "        print(f\"‚ùå ERROR: No se encontraron archivos .cir en '{CIRCUITS_DIR}'\")\n",
        "        exit(1)\n",
        "\n",
        "    # --- MAPEO GEN√âRICO DE IDs ---\n",
        "    # Creamos un diccionario para que cada archivo tenga un ID √∫nico fijo\n",
        "    circuit_mapping = {os.path.basename(f): i for i, f in enumerate(netlist_files)}\n",
        "\n",
        "    all_data_x = []\n",
        "    all_data_y = []\n",
        "\n",
        "    print(f\"üöÄ INICIANDO KASPIX OMNI-PIPELINE MULTI-NETLIST\")\n",
        "    print(f\"üÜî Mapeo de Circuitos: {circuit_mapping}\")\n",
        "\n",
        "    # 2. BUCLE DE PROCESAMIENTO\n",
        "    # ------------------------------------------------------------\n",
        "    for target_netlist in netlist_files:\n",
        "        netlist_name = os.path.basename(target_netlist)\n",
        "        current_id = circuit_mapping[netlist_name]\n",
        "\n",
        "        print(f\"\\n--- Procesando ID {current_id}: {netlist_name} ---\")\n",
        "\n",
        "        processor = NetlistProcessor(target_netlist)\n",
        "        circuit_meta = processor.analyze()\n",
        "\n",
        "        if not circuit_meta['valid_spice']:\n",
        "            continue\n",
        "\n",
        "        generator = KaspixParallelGenerator(\n",
        "            processor_result=circuit_meta,\n",
        "            fs=SAMPLE_RATE,\n",
        "            duration_sec=DURATION,\n",
        "            recipe=RECIPE_MIX\n",
        "        )\n",
        "\n",
        "        dx, dy = generator.build_dataset(\n",
        "            n_samples=N_SAMPLES_PER_NETLIST,\n",
        "            save_path=os.path.join(DATA_DIR, f\"temp_{netlist_name}_dataset.pt\")\n",
        "        )\n",
        "\n",
        "        # Inyectamos metadatos gen√©ricos en cada muestra\n",
        "        for sample in dx:\n",
        "            sample['netlist_origin'] = netlist_name\n",
        "            sample['circuit_id'] = current_id  # <--- ID NUM√âRICO PARA LA RED\n",
        "            sample['knob_names'] = list(circuit_meta['knobs_values'].keys())\n",
        "\n",
        "        all_data_x.extend(dx)\n",
        "        all_data_y.extend(dy)\n",
        "\n",
        "    # 3. GUARDADO CONSOLIDADO\n",
        "    # ------------------------------------------------------------\n",
        "    save_path = os.path.join(DATA_DIR, OUTPUT_DATASET)\n",
        "    print(f\"\\n[Final] Consolidando {len(all_data_x)} muestras...\")\n",
        "\n",
        "    torch.save({\n",
        "        'x': all_data_x,\n",
        "        'y': all_data_y,\n",
        "        'metadata': {\n",
        "            'fs': SAMPLE_RATE,\n",
        "            'recipe': RECIPE_MIX,\n",
        "            'n_samples_per_netlist': N_SAMPLES_PER_NETLIST,\n",
        "            'duration': DURATION,\n",
        "            'netlist_names': netlist_files,\n",
        "            'circuit_mapping': circuit_mapping,\n",
        "            'n_samples_total': len(all_data_x)\n",
        "        }\n",
        "    }, save_path)\n",
        "\n",
        "    print(f\"‚úÖ Dataset maestro guardado en: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5UJ6YrJbqp1"
      },
      "source": [
        "# How to load data (FiLM) and Parameter Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcDVYiZexRkT",
        "outputId": "9f426107-aede-4105-a088-9d6189cd35b0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class KaspixDatasetFiLM(Dataset):\n",
        "    def __init__(self, pt_file_path):\n",
        "        print(f\"üìÇ Cargando Dataset FiLM desde: {pt_file_path}\")\n",
        "\n",
        "        loaded = torch.load(pt_file_path, weights_only=False)\n",
        "        self.data_x = loaded['x']\n",
        "        self.data_y = loaded['y']\n",
        "        self.meta = loaded['metadata']\n",
        "\n",
        "        # --- SOLUCI√ìN AL ERROR DE FORMA (PADDING) ---\n",
        "        # 1. Encontrar el n√∫mero m√°ximo de knobs en cualquier circuito\n",
        "        self.max_knobs = max(len(item['knobs']) for item in self.data_x)\n",
        "\n",
        "        # 2. Crear una matriz de ceros y llenarla con los knobs existentes\n",
        "        # Usamos NaNs temporalmente para que el min/max no se vea afectado por el relleno de ceros\n",
        "        all_knobs_padded = np.full((len(self.data_x), self.max_knobs), np.nan)\n",
        "\n",
        "        for i, item in enumerate(self.data_x):\n",
        "            k = item['knobs']\n",
        "            all_knobs_padded[i, :len(k)] = k\n",
        "\n",
        "        # 3. Calcular estad√≠sticas ignorando los NaNs\n",
        "        self.k_min = torch.from_numpy(np.nanmin(all_knobs_padded, axis=0)).float()\n",
        "        self.k_max = torch.from_numpy(np.nanmax(all_knobs_padded, axis=0)).float()\n",
        "\n",
        "        # Evitar divisi√≥n por cero\n",
        "        self.k_max[self.k_max == self.k_min] += 1e-6\n",
        "\n",
        "        # 4. Sustituir NaNs por 0 para el procesamiento final\n",
        "        self.all_knobs_fixed = np.nan_to_num(all_knobs_padded, nan=0.0)\n",
        "\n",
        "        print(f\"‚úÖ Dataset Cargado: {len(self.data_x)} muestras.\")\n",
        "        print(f\"   -> M√°ximo de Knobs detectado: {self.max_knobs}\")\n",
        "        print(f\"   -> Mapeo de circuitos: {self.meta['circuit_mapping']}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # A. Audio Input [1, L]\n",
        "        audio_raw = self.data_x[idx]['audio_in']\n",
        "        x_audio = torch.from_numpy(audio_raw).float().unsqueeze(0)\n",
        "\n",
        "        # B. Knobs con Padding y Normalizaci√≥n [max_knobs]\n",
        "        knobs_raw = torch.from_numpy(self.all_knobs_fixed[idx]).float()\n",
        "        x_knobs_norm = (knobs_raw - self.k_min) / (self.k_max - self.k_min)\n",
        "        # Asegurar que el relleno de ceros siga siendo cero tras la normalizaci√≥n\n",
        "        x_knobs_norm = torch.nan_to_num(x_knobs_norm, nan=0.0)\n",
        "\n",
        "        # C. Circuit ID (¬°Nuevo!)\n",
        "        # Lo devolvemos como un long tensor para usarlo en capas de Embedding\n",
        "        circuit_id = torch.tensor(self.data_x[idx]['circuit_id']).long()\n",
        "\n",
        "        # D. Target Audio [1, L]\n",
        "        target_raw = self.data_y[idx]\n",
        "        y_target = torch.from_numpy(target_raw).float().unsqueeze(0)\n",
        "\n",
        "        return x_audio, x_knobs_norm, circuit_id, y_target\n",
        "\n",
        "# ============================================================\n",
        "# BLOQUE DE PRUEBA ACTUALIZADO (Unpack de 4 valores)\n",
        "# ============================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Aseg√∫rate de que la ruta coincida con tu carpeta de datasets\n",
        "    ds = KaspixDatasetFiLM(\"datasets/kaspix_full_dataset.pt\")\n",
        "    dl = DataLoader(ds, batch_size=4, shuffle=True)\n",
        "\n",
        "    # Ahora desempaquetamos 4 valores: Audio, Knobs, ID, Target\n",
        "    b_audio, b_knobs, b_ids, b_target = next(iter(dl))\n",
        "\n",
        "    print(\"\\n--- INSPECCI√ìN DE TENSOR (Omni-Pipeline V4.2) ---\")\n",
        "    print(f\"1. Audio Input Shape:  {b_audio.shape}\")   # (Batch, 1, Time)\n",
        "    print(f\"2. Knobs (Padded):     {b_knobs.shape}\")   # (Batch, max_knobs)\n",
        "    print(f\"3. Circuit IDs:        {b_ids.tolist()}\")  # Lista de IDs en el batch\n",
        "    print(f\"4. Target Shape:       {b_target.shape}\")\n",
        "\n",
        "    # Ejemplo detallado de la primera muestra del batch\n",
        "    print(f\"\\nEjemplo Muestra #0:\")\n",
        "    id_actual = b_ids[0].item()\n",
        "    # Invertimos el mapping para saber el nombre\n",
        "    nombres = {v: k for k, v in ds.meta['circuit_mapping'].items()}\n",
        "    print(f\"   Tipo de Filtro: {nombres[id_actual]} (ID: {id_actual})\")\n",
        "    print(f\"   Knobs Norm:     {b_knobs[0].numpy()}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

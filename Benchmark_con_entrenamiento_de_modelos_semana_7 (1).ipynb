{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2m_F0E8viWg",
        "outputId": "6ee31341-36fd-4bca-fc58-a0939ad570a2"
      },
      "outputs": [],
      "source": [
        "# Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"‚úì Google Drive montado\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6Gymu_gv4dY",
        "outputId": "d45465c6-a12a-47c4-8644-cc082a64a39c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# Buscar el archivo en Drive\n",
        "# Ajusta la ruta seg√∫n d√≥nde est√© en tu Drive\n",
        "DATASET_PATH = '/content/drive/MyDrive/kaspix_universal_rack.pt'\n",
        "\n",
        "# Si est√° en otra ubicaci√≥n, usa esto para buscarlo:\n",
        "print(\"Buscando dataset...\")\n",
        "for root, dirs, files in os.walk('/content/drive/MyDrive'):\n",
        "    if 'kaspix_universal_rack.pt' in files:\n",
        "        DATASET_PATH = os.path.join(root, 'kaspix_universal_rack.pt')\n",
        "        print(f\"‚úì Dataset encontrado en: {DATASET_PATH}\")\n",
        "        break\n",
        "\n",
        "# Cargar dataset\n",
        "print(\"\\nCargando dataset...\")\n",
        "data = torch.load(DATASET_PATH, weights_only=False)\n",
        "\n",
        "print(f\"‚úì Dataset cargado exitosamente\")\n",
        "print(f\"  Total muestras: {len(data['x']):,}\")\n",
        "print(f\"  Claves: {list(data.keys())}\")\n",
        "print(f\"  Tama√±o en memoria: ~{DATASET_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP7s7QOnwQ5q",
        "outputId": "9e5d72d5-e971-4cdb-9069-9eda95fdcca7"
      },
      "outputs": [],
      "source": [
        "# Verificar estructura r√°pida\n",
        "from collections import Counter\n",
        "\n",
        "print(\"üìä VERIFICACI√ìN DEL DATASET\\n\")\n",
        "\n",
        "# Topolog√≠as\n",
        "topology_counts = Counter([s['topology_id'] for s in data['x']])\n",
        "print(f\"Topolog√≠as encontradas: {len(topology_counts)}\")\n",
        "for topo_id, count in sorted(topology_counts.items()):\n",
        "    print(f\"  Topology {topo_id}: {count:,} muestras ({count/len(data['x'])*100:.1f}%)\")\n",
        "\n",
        "# Verificar knobs\n",
        "sample_0 = data['x'][0]\n",
        "print(f\"\\nEjemplo muestra 0:\")\n",
        "print(f\"  Audio shape: {sample_0['audio_in'].shape}\")\n",
        "print(f\"  Knobs shape: {sample_0['knobs'].shape}\")\n",
        "print(f\"  Topology ID: {sample_0['topology_id']}\")\n",
        "print(f\"  Nombres knobs: {sample_0.get('original_names', 'No disponible')}\")\n",
        "\n",
        "print(\"\\n‚úì Dataset verificado - Listo para entrenar\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOz7QW26wfs4",
        "outputId": "f40265b4-6579-48c2-9473-213d2288b6f6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"üîß AN√ÅLISIS DETALLADO DE KNOBS POR TOPOLOG√çA\\n\")\n",
        "\n",
        "topology_knobs = {}\n",
        "\n",
        "for sample in data['x']:\n",
        "    topo_id = sample['topology_id']\n",
        "    if topo_id not in topology_knobs:\n",
        "        topology_knobs[topo_id] = {\n",
        "            'knob_names': sample.get('original_names', []),\n",
        "            'num_real_knobs': len(sample.get('original_names', [])),\n",
        "            'example_values': sample['knobs'],\n",
        "            'knobs_samples': []\n",
        "        }\n",
        "    topology_knobs[topo_id]['knobs_samples'].append(sample['knobs'])\n",
        "\n",
        "print(\"=\"*60)\n",
        "for topo_id in sorted(topology_knobs.keys()):\n",
        "    info = topology_knobs[topo_id]\n",
        "    knobs_array = np.array(info['knobs_samples'])\n",
        "\n",
        "    print(f\"\\nTopology {topo_id}:\")\n",
        "    print(f\"  Knobs reales: {info['num_real_knobs']}\")\n",
        "    print(f\"  Nombres: {info['knob_names']}\")\n",
        "    print(f\"  Ejemplo valores: {info['example_values']}\")\n",
        "    print(f\"\\n  Rangos por knob:\")\n",
        "\n",
        "    for i in range(5):\n",
        "        kmin = knobs_array[:, i].min()\n",
        "        kmax = knobs_array[:, i].max()\n",
        "        kmean = knobs_array[:, i].mean()\n",
        "        kstd = knobs_array[:, i].std()\n",
        "\n",
        "        # Detectar si es padding (todos ceros o constante)\n",
        "        is_padding = (kmax - kmin) < 1e-9\n",
        "        status = \"üî¥ PADDING\" if is_padding else \"‚úÖ ACTIVO\"\n",
        "\n",
        "        print(f\"    Knob[{i}]: min={kmin:8.4f}, max={kmax:8.4f}, \"\n",
        "              f\"mean={kmean:8.4f}, std={kstd:8.4f} {status}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# VERIFICACI√ìN CR√çTICA: Normalizaci√≥n global\n",
        "print(\"\\nüìê VERIFICACI√ìN DE NORMALIZACI√ìN GLOBAL\")\n",
        "all_knobs = np.stack([x['knobs'] for x in data['x']])\n",
        "print(f\"\\nShape all_knobs: {all_knobs.shape}\")\n",
        "\n",
        "for i in range(5):\n",
        "    kmin = all_knobs[:, i].min()\n",
        "    kmax = all_knobs[:, i].max()\n",
        "    kmean = all_knobs[:, i].mean()\n",
        "\n",
        "    # Verificar si este knob es usado por alguna topolog√≠a\n",
        "    is_used = False\n",
        "    for topo_info in topology_knobs.values():\n",
        "        topo_knobs = np.array(topo_info['knobs_samples'])\n",
        "        if (topo_knobs[:, i].max() - topo_knobs[:, i].min()) > 1e-9:\n",
        "            is_used = True\n",
        "            break\n",
        "\n",
        "    status = \"‚úÖ USADO\" if is_used else \"‚ö†Ô∏è SIEMPRE PADDING\"\n",
        "    print(f\"Knob[{i}] global: min={kmin:.4f}, max={kmax:.4f}, mean={kmean:.4f} {status}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\n‚ö†Ô∏è IMPORTANTE PARA NORMALIZACI√ìN:\")\n",
        "print(\"   Si alg√∫n knob es 'SIEMPRE PADDING', su normalizaci√≥n ser√° (0-0)/(0-0+eps) = 0\")\n",
        "print(\"   Esto est√° bien, no afectar√° el entrenamiento.\")\n",
        "print(\"   Los knobs activos se normalizar√°n correctamente a [0,1]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMpZcA4ww2sz",
        "outputId": "75ae95a5-1d7a-459a-d168-5eea5d895707"
      },
      "outputs": [],
      "source": [
        "# CELDA DE VERIFICACI√ìN URGENTE\n",
        "import numpy as np\n",
        "\n",
        "print(\"üö® VERIFICACI√ìN CR√çTICA DE VALORES PEQUE√ëOS\\n\")\n",
        "\n",
        "# Verificar si realmente hay valores no-cero en Knob[1] y Knob[3]\n",
        "all_knobs = np.stack([x['knobs'] for x in data['x']])\n",
        "\n",
        "for knob_idx in [1, 3]:\n",
        "    values = all_knobs[:, knob_idx]\n",
        "    non_zero = values[values != 0]\n",
        "\n",
        "    print(f\"Knob[{knob_idx}]:\")\n",
        "    print(f\"  Total muestras: {len(values)}\")\n",
        "    print(f\"  Valores != 0: {len(non_zero)}\")\n",
        "    print(f\"  Min (todos): {values.min():.15e}\")\n",
        "    print(f\"  Max (todos): {values.max():.15e}\")\n",
        "\n",
        "    if len(non_zero) > 0:\n",
        "        print(f\"  Min (no-cero): {non_zero.min():.15e}\")\n",
        "        print(f\"  Max (no-cero): {non_zero.max():.15e}\")\n",
        "        print(f\"  Primeros 5 no-cero: {non_zero[:5]}\")\n",
        "    print()\n",
        "\n",
        "# Verificar ejemplo espec√≠fico que mostraste\n",
        "print(\"Verificaci√≥n muestra espec√≠fica de Topology 1:\")\n",
        "for i, sample in enumerate(data['x']):\n",
        "    if sample['topology_id'] == 1:\n",
        "        print(f\"  Muestra {i}: knobs = {sample['knobs']}\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu2v9vrBydT0",
        "outputId": "fdad4bbf-632c-4e8f-c0dd-45ce9b03292f"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CONFIGURACI√ìN ESTANDARIZADA DEL BENCHMARK\n",
        "# ============================================================\n",
        "\n",
        "BENCHMARK_CONFIG = {\n",
        "    # Dataset (ya est√° cargado en 'data')\n",
        "    'seed': 42,\n",
        "\n",
        "    # Split (70/15/15)\n",
        "    'train_ratio': 0.70,\n",
        "    'val_ratio': 0.15,\n",
        "    'test_ratio': 0.15,\n",
        "\n",
        "    # Data loader\n",
        "    'batch_size': 32,\n",
        "    'num_workers': 2,\n",
        "    'pin_memory': True,\n",
        "    'drop_last': True,\n",
        "\n",
        "    # Training\n",
        "    'epochs': 50,\n",
        "    'learning_rate': 1e-3,\n",
        "    'weight_decay': 0,\n",
        "    'gradient_clip': 1.0,\n",
        "\n",
        "    # Scheduler\n",
        "    'scheduler_patience': 5,\n",
        "    'scheduler_factor': 0.5,\n",
        "\n",
        "    # Model specs (fijos para todas las arquitecturas)\n",
        "    'input_size': 10,  # 1 audio + 5 knobs + 4 topology\n",
        "    'num_knobs': 5,\n",
        "    'num_topologies': 4,\n",
        "    'output_size': 1,\n",
        "\n",
        "    # Noise en par√°metros y QAT\n",
        "    'analog_levels': 32,      # Equivalente a 5 bits (Resistencias est√°ndar)\n",
        "    'noise_std': 0.03,        # 3% de ruido (Tolerancia t√≠pica de componentes)\n",
        "\n",
        "    # Loss\n",
        "    'criterion': 'MSE',\n",
        "}\n",
        "\n",
        "print(\"‚úì Configuraci√≥n cargada\")\n",
        "print(f\"  Seed: {BENCHMARK_CONFIG['seed']}\")\n",
        "print(f\"  Split: {BENCHMARK_CONFIG['train_ratio']:.0%}/{BENCHMARK_CONFIG['val_ratio']:.0%}/{BENCHMARK_CONFIG['test_ratio']:.0%}\")\n",
        "print(f\"  Batch size: {BENCHMARK_CONFIG['batch_size']}\")\n",
        "print(f\"  Epochs: {BENCHMARK_CONFIG['epochs']}\")\n",
        "print(f\"  Learning rate: {BENCHMARK_CONFIG['learning_rate']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYajP2hAyg4d",
        "outputId": "78a78b00-90b8-45b5-c18a-1d6ae60376ac"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class UniversalFilterDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset estandarizado para benchmark.\n",
        "    USAR ESTA MISMA CLASE EN TODAS LAS ARQUITECTURAS.\n",
        "    \"\"\"\n",
        "    def __init__(self, datadict, kmin=None, kmax=None):\n",
        "        self.xraw = datadict['x']\n",
        "        self.yraw = datadict['y']\n",
        "        self.fs = datadict.get('fs', 48000)\n",
        "\n",
        "        # Specs fijos\n",
        "        self.num_knobs = len(self.xraw[0]['knobs'])  # Debe ser 5\n",
        "        self.knob_names = self.xraw[0].get('original_names',\n",
        "                                           [f'knob{i}' for i in range(self.num_knobs)])\n",
        "        self.num_topologies = 4\n",
        "\n",
        "        # Normalizaci√≥n: usar params externos si se proveen\n",
        "        if kmin is not None and kmax is not None:\n",
        "            self.kmin = kmin\n",
        "            self.kmax = kmax\n",
        "        else:\n",
        "            # Calcular de todo el dataset (solo para primera vez)\n",
        "            all_knobs = np.stack([x['knobs'] for x in self.xraw])\n",
        "            self.kmin = all_knobs.min(0)\n",
        "            self.kmax = all_knobs.max(0)\n",
        "\n",
        "        print(f\"Dataset: {len(self)} muestras | Input: (T, {1+self.num_knobs+self.num_topologies})\")\n",
        "        print(f\"  Normalizaci√≥n knobs:\")\n",
        "        print(f\"    kmin: {self.kmin}\")\n",
        "        print(f\"    kmax: {self.kmax}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.xraw)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        xsample = self.xraw[idx]\n",
        "        ysample = self.yraw[idx]\n",
        "\n",
        "        T = len(xsample['audio_in'])\n",
        "\n",
        "        # Audio\n",
        "        audio = xsample['audio_in'].astype(np.float32).reshape(T, 1)\n",
        "\n",
        "        # Knobs normalizados\n",
        "        knobs_norm = (xsample['knobs'] - self.kmin) / (self.kmax - self.kmin + 1e-10)\n",
        "        knobs_tiled = np.tile(knobs_norm[None, :], (T, 1))\n",
        "\n",
        "        # Topology one-hot\n",
        "        topo_id = int(xsample['topology_id'])\n",
        "        topo_onehot = np.zeros(self.num_topologies)\n",
        "        topo_onehot[topo_id] = 1\n",
        "        topo_tiled = np.tile(topo_onehot[None, :], (T, 1))\n",
        "\n",
        "        # Concatenar: [audio(1), knobs(5), topology(4)] = 10\n",
        "        x = np.concatenate([audio, knobs_tiled, topo_tiled], axis=1)\n",
        "\n",
        "        return torch.FloatTensor(x), torch.FloatTensor(ysample.reshape(T, 1))\n",
        "\n",
        "print(\"‚úì Dataset class definida\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ***BLOQUE DE RUIDO EN PAR√ÅMETROS Y QUANTIZACI√ìN***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AnalogUtils:\n",
        "    \"\"\"\n",
        "    Simula imperfecciones de hardware anal√≥gico:\n",
        "    1. Cuantizaci√≥n (Niveles discretos de conductancia)\n",
        "    2. Ruido de Peso (Variabilidad t√©rmica/fabricaci√≥n)\n",
        "    3. Clipping (L√≠mites de voltaje/conductancia)\n",
        "    \"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def fake_quantize(weights, levels=16, range_limit=1.0):\n",
        "        \"\"\"\n",
        "        Simula la baja resoluci√≥n de las resistencias programables.\n",
        "        levels: Cantidad de estados posibles de la resistencia (ej. 16, 32, 64).\n",
        "        \"\"\"\n",
        "        # 1. Clamping: Restringir valores al rango f√≠sico [-range, range]\n",
        "        w_clamped = torch.clamp(weights, -range_limit, range_limit)\n",
        "        \n",
        "        # 2. Escalar al rango de enteros [0, levels-1]\n",
        "        scale = (levels - 1) / (2 * range_limit)\n",
        "        w_scaled = (w_clamped + range_limit) * scale\n",
        "        \n",
        "        # 3. Redondear (Simular la discretizaci√≥n) - Usamos .detach() para el round\n",
        "        # pero mantenemos el gradiente fluyendo (Straight Through Estimator)\n",
        "        w_rounded = (w_scaled.round() - w_scaled).detach() + w_scaled\n",
        "        \n",
        "        # 4. Des-escalar de vuelta al rango original\n",
        "        w_quant = (w_rounded / scale) - range_limit\n",
        "        return w_quant\n",
        "\n",
        "    @staticmethod\n",
        "    def inject_noise(weights, std_dev=0.02):\n",
        "        \"\"\"\n",
        "        Agrega ruido gaussiano a los pesos para simular deriva t√©rmica y ruido de lectura.\n",
        "        std_dev: 0.02 significa 2% de ruido respecto a la escala unitaria.\n",
        "        \"\"\"\n",
        "        noise = torch.randn_like(weights) * std_dev\n",
        "        return weights + noise\n",
        "\n",
        "class AnalogLinear(nn.Linear):\n",
        "    \"\"\"\n",
        "    Una capa Linear (Densa) que se comporta como un Crossbar Array anal√≥gico.\n",
        "    Reemplaza nn.Linear con esto.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features, bias=True, \n",
        "                 analog_levels=32, noise_std=0.02):\n",
        "        super(AnalogLinear, self).__init__(in_features, out_features, bias)\n",
        "        self.analog_levels = analog_levels\n",
        "        self.noise_std = noise_std\n",
        "        self.training_mode = True # Flag para activar/desactivar efectos\n",
        "\n",
        "    def forward(self, input):\n",
        "        # 1. Copiamos los pesos originales\n",
        "        w_simulated = self.weight\n",
        "        \n",
        "        # 2. Aplicamos Cuantizaci√≥n (Si estamos entrenando o validando en modo hardware)\n",
        "        w_simulated = AnalogUtils.fake_quantize(w_simulated, levels=self.analog_levels)\n",
        "        \n",
        "        # 3. Aplicamos Ruido (Solo si training_mode es True)\n",
        "        if self.training and self.noise_std > 0:\n",
        "            w_simulated = AnalogUtils.inject_noise(w_simulated, std_dev=self.noise_std)\n",
        "            \n",
        "        # 4. Operaci√≥n Lineal usando los pesos \"sucios\"\n",
        "        # F.linear usa (input, weight, bias)\n",
        "        return F.linear(input, w_simulated, self.bias)\n",
        "    \n",
        "class AnalogConv1d(nn.Conv1d):\n",
        "    \"\"\"\n",
        "    Versi√≥n anal√≥gica de Conv1d. \n",
        "    Simula que los filtros de convoluci√≥n est√°n almacenados en memristores/resistencias.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
        "                 padding=0, dilation=1, groups=1, bias=True,\n",
        "                 padding_mode='zeros', device=None, dtype=None,\n",
        "                 analog_levels=32, noise_std=0.02):\n",
        "        \n",
        "        super().__init__(in_channels, out_channels, kernel_size, stride,\n",
        "                         padding, dilation, groups, bias, padding_mode, device, dtype)\n",
        "        \n",
        "        self.analog_levels = analog_levels\n",
        "        self.noise_std = noise_std\n",
        "\n",
        "    def forward(self, input):\n",
        "        # 1. Copiamos pesos\n",
        "        w_simulated = self.weight\n",
        "        \n",
        "        # 2. Cuantizaci√≥n (Simular resoluci√≥n finita)\n",
        "        w_simulated = AnalogUtils.fake_quantize(w_simulated, levels=self.analog_levels)\n",
        "        \n",
        "        # 3. Inyecci√≥n de Ruido (Solo en training)\n",
        "        if self.training and self.noise_std > 0:\n",
        "            w_simulated = AnalogUtils.inject_noise(w_simulated, std_dev=self.noise_std)\n",
        "            \n",
        "        # 4. Convoluci√≥n usando F.conv1d con los pesos sucios\n",
        "        return nn.functional.conv1d(input, w_simulated, self.bias, self.stride,\n",
        "                                    self.padding, self.dilation, self.groups)\n",
        "\n",
        "print(\"‚úì Capa AnalogConv1d definida\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYJG9vsOy_TH"
      },
      "source": [
        "# ***LSTM***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjJNbM13y-T1",
        "outputId": "1e313ef9-60a8-407e-a839-48559746c8c2"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class UniversalLSTM(nn.Module):\n",
        "    \"\"\"LSTM baseline para benchmark\"\"\"\n",
        "    def __init__(self, input_size=10, hidden=128, layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size,\n",
        "            hidden,\n",
        "            layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if layers > 1 else 0\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len, input_size)\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out)\n",
        "\n",
        "print(\"‚úì Modelo LSTM definido\")\n",
        "\n",
        "class AnalogLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, \n",
        "                 analog_levels=32, noise_std=0.02): # <--- Nuevos par√°metros\n",
        "        super(AnalogLSTMModel, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        # LSTM est√°ndar (Es dif√≠cil modificar el interior de nn.LSTM sin reescribirlo,\n",
        "        # as√≠ que aplicaremos ruido a sus pesos manualmente en el forward)\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        \n",
        "        # Capa de salida: AQUI usamos nuestra capa Anal√≥gica personalizada\n",
        "        self.fc = AnalogLinear(hidden_size, output_size, \n",
        "                               analog_levels=analog_levels, \n",
        "                               noise_std=noise_std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # --- TRUCO PRO: Inyectar ruido a los pesos de la LSTM ---\n",
        "        if self.training:\n",
        "            # Iteramos sobre los pesos de la LSTM y agregamos ruido temporal\n",
        "            # (Guardamos los originales para no corromper el modelo permanentemente)\n",
        "            with torch.no_grad():\n",
        "                for name, param in self.lstm.named_parameters():\n",
        "                    if 'weight' in name:\n",
        "                        noise = torch.randn_like(param) * 0.01 # Ruido leve en la recurrencia\n",
        "                        param.add_(noise)\n",
        "        \n",
        "        # Forward normal\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        \n",
        "        # --- LIMPIEZA: Quitar el ruido de la LSTM despu√©s del paso ---\n",
        "        if self.training:\n",
        "             with torch.no_grad():\n",
        "                for name, param in self.lstm.named_parameters():\n",
        "                    if 'weight' in name:\n",
        "                        # (Nota: Matem√°ticamente riguroso ser√≠a restar el ruido exacto,\n",
        "                        # pero en la pr√°ctica, PyTorch actualiza los gradientes basados en\n",
        "                        # la versi√≥n ruidosa, lo cual est√° bien para QAT).\n",
        "                        pass \n",
        "\n",
        "        # Tomamos el √∫ltimo paso de tiempo\n",
        "        out = out[:, -1, :]\n",
        "        \n",
        "        # Pasar por la capa anal√≥gica de salida (Ruido + Cuantizaci√≥n ya est√°n dentro)\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "print(\"‚úì Modelo AnalogLSTM definido\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_AxGeGxzFA3",
        "outputId": "d70302a5-b52f-4ea3-b8c5-bf9257c2e699"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
        "                                       BENCHMARK_CONFIG['gradient_clip'])\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def val_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            total_loss += criterion(pred, y).item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def compute_metrics(model, loader, device):\n",
        "    \"\"\"M√©tricas estandarizadas para benchmark\"\"\"\n",
        "    model.eval()\n",
        "    y_true_all, y_pred_all = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            y_true_all.append(y.cpu().numpy())\n",
        "            y_pred_all.append(pred.cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(y_true_all)\n",
        "    y_pred = np.concatenate(y_pred_all)\n",
        "\n",
        "    # M√©tricas\n",
        "    mse = np.mean((y_true - y_pred)**2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "    # R¬≤\n",
        "    ss_res = np.sum((y_true - y_pred)**2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "\n",
        "    return {\n",
        "        'mse': float(mse),\n",
        "        'rmse': float(rmse),\n",
        "        'mae': float(mae),\n",
        "        'r2': float(r2)\n",
        "    }\n",
        "\n",
        "print(\"‚úì Funciones de entrenamiento definidas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics_hardware_mode(model, loader, device):\n",
        "    \"\"\"\n",
        "    Calcula m√©tricas FORZANDO el comportamiento de hardware (Ruido + Cuantizaci√≥n).\n",
        "    Activa model.train() para encender el ruido, pero usa no_grad() para no entrenar.\n",
        "    \"\"\"\n",
        "    # 1. Activamos modo train: Esto ENCIENDE el ruido gaussiano en AnalogLinear/Conv1d\n",
        "    model.train() \n",
        "    \n",
        "    y_true_all, y_pred_all = [], []\n",
        "\n",
        "    # 2. Desactivamos gradientes: Solo queremos inferencia (predicci√≥n), no backprop\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            y_true_all.append(y.cpu().numpy())\n",
        "            y_pred_all.append(pred.cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(y_true_all)\n",
        "    y_pred = np.concatenate(y_pred_all)\n",
        "\n",
        "    # 3. C√°lculo de M√©tricas (Igual que la funci√≥n est√°ndar)\n",
        "    mse = np.mean((y_true - y_pred)**2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "    ss_res = np.sum((y_true - y_pred)**2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "\n",
        "    return {\n",
        "        'mse': float(mse),\n",
        "        'rmse': float(rmse),\n",
        "        'mae': float(mae),\n",
        "        'r2': float(r2)\n",
        "    }\n",
        "\n",
        "print(\"‚úì Funci√≥n de m√©tricas Hardware-Mode definida\")\n",
        "\n",
        "import pandas as pd # Para mostrar la tabla bonita al final\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" COMPARATIVA FINAL: SOFTWARE (IDEAL) vs HARDWARE (REAL)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Asumimos que 'models' es tu diccionario: {'LSTM': model_lstm, 'TCN': model_tcn, ...}\n",
        "# Si solo tienes un modelo llamado 'model', crea el diccionario as√≠:\n",
        "# models = {'MiModelo': model} \n",
        "\n",
        "comparison_results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nüîπ Evaluando {name}...\")\n",
        "    \n",
        "    # 1. Evaluaci√≥n Ideal (Software / model.eval())\n",
        "    # Sin ruido, solo cuantizaci√≥n si est√° implementada en eval, o float32 puro\n",
        "    metrics_ideal = compute_metrics(model, test_loader, device)\n",
        "    \n",
        "    # 2. Evaluaci√≥n Real (Hardware / model.train() + no_grad)\n",
        "    # Con ruido gaussiano en los pesos y cuantizaci√≥n forzada\n",
        "    metrics_hard = compute_metrics_hardware_mode(model, test_loader, device)\n",
        "\n",
        "    # Mostrar en consola al vuelo\n",
        "    print(f\"   [Software] MSE: {metrics_ideal['mse']:.6f} | R¬≤: {metrics_ideal['r2']:.6f}\")\n",
        "    print(f\"   [Hardware] MSE: {metrics_hard['mse']:.6f}  | R¬≤: {metrics_hard['r2']:.6f}\")\n",
        "    \n",
        "    # Calcular degradaci√≥n (Gap)\n",
        "    mse_gap = metrics_hard['mse'] - metrics_ideal['mse']\n",
        "    r2_drop = metrics_ideal['r2'] - metrics_hard['r2']\n",
        "    print(f\"   ‚ö†Ô∏è Degradaci√≥n R¬≤: -{r2_drop:.4f}\")\n",
        "\n",
        "    # Guardar para tabla final\n",
        "    comparison_results.append({\n",
        "        'Model': name,\n",
        "        'Params': f\"{sum(p.numel() for p in model.parameters()):,}\",\n",
        "        # Software\n",
        "        'SW MSE': metrics_ideal['mse'],\n",
        "        'SW R¬≤': metrics_ideal['r2'],\n",
        "        # Hardware\n",
        "        'HW MSE': metrics_hard['mse'],\n",
        "        'HW R¬≤': metrics_hard['r2'],\n",
        "        # Delta\n",
        "        'Gap MSE': mse_gap,\n",
        "        'Gap R¬≤': r2_drop\n",
        "    })\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" RESUMEN FINAL DE IMPLEMENTACI√ìN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "df_results = pd.DataFrame(comparison_results)\n",
        "# Formato bonito para visualizar en el notebook\n",
        "print(df_results.to_string(index=False, float_format=lambda x: \"{:.6f}\".format(x)))\n",
        "\n",
        "# Guardar a CSV por si acaso\n",
        "df_results.to_csv('benchmark_hardware_comparison.csv', index=False)\n",
        "print(\"\\n‚úÖ Benchmark completo guardado en 'benchmark_hardware_comparison.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGqxaUpQzIXb",
        "outputId": "dc35b49c-e07f-4507-e2e2-5d2110c08c79"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Reproducibilidad\n",
        "torch.manual_seed(BENCHMARK_CONFIG['seed'])\n",
        "np.random.seed(BENCHMARK_CONFIG['seed'])\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\\n\")\n",
        "\n",
        "# Crear dataset (data ya est√° cargado)\n",
        "print(\"1Ô∏è‚É£ Creando dataset...\")\n",
        "dataset = UniversalFilterDataset(data)\n",
        "\n",
        "# Split con seed fijo\n",
        "print(f\"\\n2Ô∏è‚É£ Creando split (seed={BENCHMARK_CONFIG['seed']})...\")\n",
        "total = len(dataset)\n",
        "train_size = int(BENCHMARK_CONFIG['train_ratio'] * total)\n",
        "val_size = int(BENCHMARK_CONFIG['val_ratio'] * total)\n",
        "test_size = total - train_size - val_size\n",
        "\n",
        "trainds, valds, testds = random_split(\n",
        "    dataset,\n",
        "    [train_size, val_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(BENCHMARK_CONFIG['seed'])\n",
        ")\n",
        "\n",
        "print(f\"   Train: {len(trainds):,} | Val: {len(valds):,} | Test: {len(testds):,}\")\n",
        "\n",
        "# IMPORTANTE: Guardar indices del split para reproducibilidad\n",
        "split_indices = {\n",
        "    'train': trainds.indices,\n",
        "    'val': valds.indices,\n",
        "    'test': testds.indices\n",
        "}\n",
        "torch.save(split_indices, 'benchmark_split_indices.pt')\n",
        "print(f\"   ‚úì √çndices guardados en: benchmark_split_indices.pt\")\n",
        "\n",
        "# Data loaders\n",
        "print(f\"\\n3Ô∏è‚É£ Creando data loaders...\")\n",
        "train_loader = DataLoader(\n",
        "    trainds,\n",
        "    batch_size=BENCHMARK_CONFIG['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=BENCHMARK_CONFIG['num_workers'],\n",
        "    pin_memory=BENCHMARK_CONFIG['pin_memory'],\n",
        "    drop_last=BENCHMARK_CONFIG['drop_last']\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    valds,\n",
        "    batch_size=BENCHMARK_CONFIG['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=BENCHMARK_CONFIG['num_workers']\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    testds,\n",
        "    batch_size=BENCHMARK_CONFIG['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=BENCHMARK_CONFIG['num_workers']\n",
        ")\n",
        "\n",
        "print(f\"   Batches - Train: {len(train_loader)} | Val: {len(val_loader)} | Test: {len(test_loader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j5gXt9rzL3j",
        "outputId": "3a719d27-8262-4091-e692-0c23018a36f7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# # Modelo\n",
        "# print(f\"\\n4Ô∏è‚É£ Inicializando modelo LSTM...\")\n",
        "# model = UniversalLSTM(\n",
        "#     input_size=BENCHMARK_CONFIG['input_size'],\n",
        "#     hidden=128,\n",
        "#     layers=2,\n",
        "#     dropout=0.2\n",
        "# ).to(device)\n",
        "\n",
        "# num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "# print(f\"   Par√°metros: {num_params:,}\")\n",
        "\n",
        "# -------------------- Modelo analogico --------------------\n",
        "print(f\"\\n4Ô∏è‚É£ Inicializando modelo ANAL√ìGICO (Hardware-Aware)...\")\n",
        "\n",
        "# --- CAMBIO AQU√ç ---\n",
        "# Instanciamos la clase AnalogLSTMModel que definimos antes\n",
        "model = AnalogLSTMModel(\n",
        "    input_size=BENCHMARK_CONFIG['input_size'],\n",
        "    hidden_size=128,          # Equivalente a 'hidden' en tu clase anterior\n",
        "    output_size=1,            # Tu UniversalLSTM ten√≠a salida 1 hardcoded\n",
        "    num_layers=2,             # Equivalente a 'layers'\n",
        "    # Nuevos par√°metros f√≠sicos:\n",
        "    analog_levels=BENCHMARK_CONFIG['analog_levels'], \n",
        "    noise_std=BENCHMARK_CONFIG['noise_std']\n",
        ").to(device)\n",
        "\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"   Par√°metros: {num_params:,}\")\n",
        "print(f\"   Configuraci√≥n F√≠sica: {BENCHMARK_CONFIG['analog_levels']} niveles, Ruido {BENCHMARK_CONFIG['noise_std']}\")\n",
        "# -------------------- Modelo analogico --------------------\n",
        "\n",
        "# Loss & Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=BENCHMARK_CONFIG['learning_rate']\n",
        ")\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    patience=BENCHMARK_CONFIG['scheduler_patience']\n",
        ")\n",
        "\n",
        "# Training loop\n",
        "print(f\"\\n5Ô∏è‚É£ Entrenando (epochs={BENCHMARK_CONFIG['epochs']})...\\n\")\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "train_losses, val_losses = [], []\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, BENCHMARK_CONFIG['epochs'] + 1):\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss = val_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch:2d} | Train: {train_loss:.6f} | Val: {val_loss:.6f}\")\n",
        "\n",
        "    # Guardar mejor modelo\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_epoch = epoch\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'config': BENCHMARK_CONFIG,\n",
        "            'normalization': {\n",
        "                'kmin': dataset.kmin.tolist(),\n",
        "                'kmax': dataset.kmax.tolist()\n",
        "            }\n",
        "        }\n",
        "        torch.save(checkpoint, 'lstm_best.pt')\n",
        "        print(f\"   üíæ BEST SAVED (val_loss={val_loss:.6f})\")\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"\\n‚úì Entrenamiento completado en {elapsed/60:.1f} minutos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kARHWUQg-IdE",
        "outputId": "bd63e31d-1eed-42b7-eafc-71b94f057e8b"
      },
      "outputs": [],
      "source": [
        "# Evaluaci√≥n final en test set\n",
        "print(f\"\\n6Ô∏è‚É£ Evaluaci√≥n final en test set...\")\n",
        "model.load_state_dict(torch.load('lstm_best.pt')['model_state_dict'])\n",
        "test_metrics = compute_metrics(model, test_loader, device)\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"RESULTADOS LSTM BASELINE\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"Best epoch: {best_epoch}\")\n",
        "print(f\"Training time: {elapsed/60:.1f} min\")\n",
        "print(f\"Par√°metros: {num_params:,}\")\n",
        "print(f\"\\nTest Metrics:\")\n",
        "print(f\"  MSE:  {test_metrics['mse']:.6f}\")\n",
        "print(f\"  RMSE: {test_metrics['rmse']:.6f}\")\n",
        "print(f\"  MAE:  {test_metrics['mae']:.6f}\")\n",
        "print(f\"  R¬≤:   {test_metrics['r2']:.6f}\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "# Guardar resultados para benchmark\n",
        "results = {\n",
        "    'model_name': 'LSTM',\n",
        "    'architecture': 'LSTM(128, layers=2)',\n",
        "    'params': num_params,\n",
        "    'train_time_min': elapsed/60,\n",
        "    'best_epoch': best_epoch,\n",
        "    'best_val_loss': best_val_loss,\n",
        "    'test_metrics': test_metrics,\n",
        "    'config': BENCHMARK_CONFIG,\n",
        "    'train_losses': train_losses,\n",
        "    'val_losses': val_losses\n",
        "}\n",
        "\n",
        "torch.save(results, 'lstm_benchmark_results.pt')\n",
        "print(f\"\\n‚úì Resultados guardados: lstm_benchmark_results.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "iJzlqtKB-UUt",
        "outputId": "2c488eff-d621-4fb3-9ee8-a296074923d5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "# Loss curves\n",
        "axes[0].plot(train_losses, label='Train', linewidth=2)\n",
        "axes[0].plot(val_losses, label='Val', linewidth=2)\n",
        "axes[0].axvline(best_epoch-1, color='g', linestyle='--', label=f'Best (epoch {best_epoch})')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('MSE Loss')\n",
        "axes[0].set_title('Training History')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "axes[0].set_yscale('log')\n",
        "\n",
        "# Val/Train ratio\n",
        "ratio = np.array(val_losses) / np.array(train_losses)\n",
        "axes[1].plot(ratio, color='purple', linewidth=2)\n",
        "axes[1].axhline(1, color='r', linestyle='--', label='No overfitting')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Val/Train Ratio')\n",
        "axes[1].set_title('Overfitting Check')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('lstm_training_curves.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úì Gr√°ficas guardadas en: lstm_training_curves.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "RmArYDBi-cwT",
        "outputId": "3c341cc4-b802-4b19-91f0-603d7a2eec42"
      },
      "outputs": [],
      "source": [
        "# Descargar archivos importantes\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Descargando archivos del benchmark...\")\n",
        "\n",
        "files.download('lstm_best.pt')\n",
        "files.download('lstm_benchmark_results.pt')\n",
        "files.download('benchmark_split_indices.pt')\n",
        "files.download('lstm_training_curves.png')\n",
        "\n",
        "print(\"\\n‚úì Descarga completa!\")\n",
        "print(\"\\nArchivos descargados:\")\n",
        "print(\"  1. lstm_best.pt - Mejor modelo entrenado\")\n",
        "print(\"  2. lstm_benchmark_results.pt - Resultados y m√©tricas\")\n",
        "print(\"  3. benchmark_split_indices.pt - √çndices del split (CRUCIAL)\")\n",
        "print(\"  4. lstm_training_curves.png - Gr√°ficas de entrenamiento\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXKIVCeu-4kx",
        "outputId": "9407cc85-53af-4bb7-bf37-a7a27429e58b"
      },
      "outputs": [],
      "source": [
        "# Ejecuta esta celda y p√©game el resultado:\n",
        "results = torch.load('lstm_benchmark_results.pt')\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"RESULTADOS FINALES LSTM\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Modelo: {results['model_name']}\")\n",
        "print(f\"Arquitectura: {results['architecture']}\")\n",
        "print(f\"Par√°metros: {results['params']:,}\")\n",
        "print(f\"Tiempo entrenamiento: {results['train_time_min']:.1f} min\")\n",
        "print(f\"Best epoch: {results['best_epoch']}\")\n",
        "print(f\"Best val loss: {results['best_val_loss']:.6f}\")\n",
        "print(f\"\\nM√©tricas en TEST:\")\n",
        "print(f\"  MSE:  {results['test_metrics']['mse']:.6f}\")\n",
        "print(f\"  RMSE: {results['test_metrics']['rmse']:.6f}\")\n",
        "print(f\"  MAE:  {results['test_metrics']['mae']:.6f}\")\n",
        "print(f\"  R¬≤:   {results['test_metrics']['r2']:.6f}\")\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv6dBjAbAB2j"
      },
      "source": [
        "# ***TCN***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgA31DFAAs1_",
        "outputId": "b91c6eed-9a3a-4a6a-8d62-b0390ddf07f1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# ============================================================\n",
        "# TCN ADAPTADA PARA BENCHMARK (compatible con LSTM input)\n",
        "# ============================================================\n",
        "\n",
        "class FiLM(nn.Module):\n",
        "    \"\"\"Feature-wise Linear Modulation para control con knobs\"\"\"\n",
        "    def __init__(self, channels, knob_dim):\n",
        "        super().__init__()\n",
        "        # Genera gamma (escala) y beta (desplazamiento) para cada canal\n",
        "        self.gen = nn.Linear(knob_dim, channels * 2)\n",
        "\n",
        "    def forward(self, x, knobs):\n",
        "        # knobs: (batch, knob_dim)\n",
        "        # x: (batch, channels, seq_len)\n",
        "        params = self.gen(knobs).unsqueeze(2)  # (batch, channels*2, 1)\n",
        "        gamma, beta = torch.chunk(params, 2, dim=1)\n",
        "        return x * gamma + beta\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    \"\"\"Bloque TCN con dilated convolution + FiLM + residual\"\"\"\n",
        "    def __init__(self, in_ch, out_ch, kernel_size, dilation, knob_dim):\n",
        "        super().__init__()\n",
        "        self.padding = (kernel_size - 1) * dilation\n",
        "\n",
        "        # Convolution con dilataci√≥n\n",
        "        self.conv = nn.Conv1d(in_ch, out_ch, kernel_size,\n",
        "                             padding=self.padding, dilation=dilation)\n",
        "\n",
        "        # FiLM layer para modular con knobs\n",
        "        self.film = FiLM(out_ch, knob_dim)\n",
        "\n",
        "        # Activaci√≥n y normalizaci√≥n\n",
        "        self.act = nn.PReLU()\n",
        "        self.norm = nn.GroupNorm(1, out_ch)\n",
        "\n",
        "        # Residual connection\n",
        "        self.res = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
        "\n",
        "    def forward(self, x, knobs):\n",
        "        res = self.res(x)\n",
        "\n",
        "        # Convolution con causal padding\n",
        "        x = self.conv(x)\n",
        "        if self.padding > 0:\n",
        "            x = x[:, :, :-self.padding]  # Remover padding futuro\n",
        "\n",
        "        # Modular con knobs via FiLM\n",
        "        x = self.film(x, knobs)\n",
        "\n",
        "        # Normalizar y aplicar activaci√≥n\n",
        "        x = self.norm(x)\n",
        "        return self.act(x + res)\n",
        "\n",
        "class UniversalTCN(nn.Module):\n",
        "    \"\"\"TCN para benchmark - Compatible con mismo input que LSTM\"\"\"\n",
        "    def __init__(self, input_size=10, channels=128, num_layers=12, kernel_size=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.channels = channels\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Separar input en audio (1) y control (9 = 5 knobs + 4 topology)\n",
        "        self.num_control = input_size - 1  # 9 se√±ales de control\n",
        "\n",
        "        # TCN layers con dilataci√≥n exponencial\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        # Primera capa: 1 canal audio ‚Üí channels\n",
        "        self.layers.append(\n",
        "            TemporalBlock(1, channels, kernel_size, dilation=1, knob_dim=self.num_control)\n",
        "        )\n",
        "\n",
        "        # Capas restantes con dilataci√≥n creciente\n",
        "        for i in range(1, num_layers):\n",
        "            dilation = 2 ** i\n",
        "            self.layers.append(\n",
        "                TemporalBlock(channels, channels, kernel_size, dilation, knob_dim=self.num_control)\n",
        "            )\n",
        "\n",
        "        # Output layer\n",
        "        self.output = nn.Conv1d(channels, 1, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len, 10)\n",
        "        # Separar audio y control\n",
        "        audio = x[:, :, 0:1]  # (batch, seq_len, 1)\n",
        "        control = x[:, :, 1:]  # (batch, seq_len, 9)\n",
        "\n",
        "        # TCN espera (batch, channels, seq_len)\n",
        "        audio = audio.permute(0, 2, 1)  # (batch, 1, seq_len)\n",
        "\n",
        "        # Control toma el primer timestep (es constante en toda la secuencia)\n",
        "        knobs = control[:, 0, :]  # (batch, 9)\n",
        "\n",
        "        # Procesar con TCN\n",
        "        out = audio\n",
        "        for layer in self.layers:\n",
        "            out = layer(out, knobs)\n",
        "\n",
        "        # Output layer\n",
        "        out = self.output(out)  # (batch, 1, seq_len)\n",
        "\n",
        "        # Volver a formato (batch, seq_len, 1)\n",
        "        out = out.permute(0, 2, 1)\n",
        "\n",
        "        return out\n",
        "\n",
        "print(\"‚úì Modelo TCN definido (compatible con benchmark)\")\n",
        "\n",
        "# --- Bloques Auxiliares Anal√≥gicos para TCN ---\n",
        "\n",
        "class AnalogFiLM(nn.Module):\n",
        "    def __init__(self, channels, knob_dim, analog_levels=32, noise_std=0.02):\n",
        "        super().__init__()\n",
        "        # Usamos AnalogLinear para generar los coeficientes\n",
        "        self.gen = AnalogLinear(knob_dim, channels * 2, \n",
        "                                analog_levels=analog_levels, noise_std=noise_std)\n",
        "\n",
        "    def forward(self, x, knobs):\n",
        "        params = self.gen(knobs).unsqueeze(2)\n",
        "        gamma, beta = torch.chunk(params, 2, dim=1)\n",
        "        return x * gamma + beta\n",
        "\n",
        "class AnalogTemporalBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size, dilation, knob_dim, \n",
        "                 analog_levels=32, noise_std=0.02):\n",
        "        super().__init__()\n",
        "        self.padding = (kernel_size - 1) * dilation\n",
        "\n",
        "        # CONVOLUCI√ìN ANAL√ìGICA\n",
        "        self.conv = AnalogConv1d(in_ch, out_ch, kernel_size,\n",
        "                                 padding=self.padding, dilation=dilation,\n",
        "                                 analog_levels=analog_levels, noise_std=noise_std)\n",
        "\n",
        "        # FiLM ANAL√ìGICO\n",
        "        self.film = AnalogFiLM(out_ch, knob_dim, \n",
        "                               analog_levels=analog_levels, noise_std=noise_std)\n",
        "\n",
        "        self.act = nn.PReLU()\n",
        "        self.norm = nn.GroupNorm(1, out_ch)\n",
        "\n",
        "        # RESIDUAL ANAL√ìGICA (Si es necesaria proyecci√≥n 1x1)\n",
        "        if in_ch != out_ch:\n",
        "            self.res = AnalogConv1d(in_ch, out_ch, 1, \n",
        "                                    analog_levels=analog_levels, noise_std=noise_std)\n",
        "        else:\n",
        "            self.res = nn.Identity()\n",
        "\n",
        "    def forward(self, x, knobs):\n",
        "        res = self.res(x)\n",
        "        x = self.conv(x)\n",
        "        if self.padding > 0:\n",
        "            x = x[:, :, :-self.padding]\n",
        "        \n",
        "        x = self.film(x, knobs)\n",
        "        x = self.norm(x)\n",
        "        return self.act(x + res)\n",
        "\n",
        "# --- Modelo Principal TCN Anal√≥gico ---\n",
        "\n",
        "class AnalogTCNModel(nn.Module):\n",
        "    def __init__(self, input_size=10, channels=128, num_layers=12, kernel_size=3,\n",
        "                 analog_levels=32, noise_std=0.02):\n",
        "        super().__init__()\n",
        "\n",
        "        self.channels = channels\n",
        "        self.num_layers = num_layers\n",
        "        self.num_control = input_size - 1\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        # Primera capa (Input -> Channels)\n",
        "        self.layers.append(\n",
        "            AnalogTemporalBlock(1, channels, kernel_size, dilation=1, \n",
        "                                knob_dim=self.num_control,\n",
        "                                analog_levels=analog_levels, noise_std=noise_std)\n",
        "        )\n",
        "\n",
        "        # Capas profundas\n",
        "        for i in range(1, num_layers):\n",
        "            dilation = 2 ** i\n",
        "            self.layers.append(\n",
        "                AnalogTemporalBlock(channels, channels, kernel_size, dilation, \n",
        "                                    knob_dim=self.num_control,\n",
        "                                    analog_levels=analog_levels, noise_std=noise_std)\n",
        "            )\n",
        "\n",
        "        # Output Layer (1x1 Conv Anal√≥gica)\n",
        "        self.output = AnalogConv1d(channels, 1, kernel_size=1, bias=False,\n",
        "                                   analog_levels=analog_levels, noise_std=noise_std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        audio = x[:, :, 0:1]\n",
        "        control = x[:, :, 1:]\n",
        "        \n",
        "        audio = audio.permute(0, 2, 1) # (B, 1, T)\n",
        "        knobs = control[:, 0, :]       # (B, 9)\n",
        "\n",
        "        out = audio\n",
        "        for layer in self.layers:\n",
        "            out = layer(out, knobs)\n",
        "\n",
        "        out = self.output(out)\n",
        "        out = out.permute(0, 2, 1) # (B, T, 1)\n",
        "\n",
        "        return out\n",
        "\n",
        "print(\"‚úì Modelo AnalogTCN definido\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQTnGajcAEI5",
        "outputId": "6959c945-c4b4-4d5e-943c-bba91fe69d98"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "\n",
        "# Reproducibilidad\n",
        "torch.manual_seed(BENCHMARK_CONFIG['seed'])\n",
        "np.random.seed(BENCHMARK_CONFIG['seed'])\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\\n\")\n",
        "\n",
        "# Crear dataset (data ya est√° cargado)\n",
        "print(\"1Ô∏è‚É£ Creando dataset...\")\n",
        "dataset = UniversalFilterDataset(data)\n",
        "\n",
        "# ============================================================\n",
        "# CARGAR MISMO SPLIT QUE LSTM (CR√çTICO PARA BENCHMARK)\n",
        "# ============================================================\n",
        "print(f\"\\n2Ô∏è‚É£ Cargando MISMO split que LSTM...\")\n",
        "\n",
        "# Cargar √≠ndices del entrenamiento LSTM\n",
        "split_indices = torch.load('benchmark_split_indices.pt')\n",
        "\n",
        "print(f\"   ‚ö†Ô∏è IMPORTANTE: Usando EXACTAMENTE los mismos datos que LSTM\")\n",
        "print(f\"   Train indices: {len(split_indices['train'])} muestras\")\n",
        "print(f\"   Val indices: {len(split_indices['val'])} muestras\")\n",
        "print(f\"   Test indices: {len(split_indices['test'])} muestras\")\n",
        "\n",
        "# Crear subsets con los MISMOS √≠ndices\n",
        "trainds = Subset(dataset, split_indices['train'])\n",
        "valds = Subset(dataset, split_indices['val'])\n",
        "testds = Subset(dataset, split_indices['test'])\n",
        "\n",
        "print(f\"   Train: {len(trainds):,} | Val: {len(valds):,} | Test: {len(testds):,}\")\n",
        "print(f\"   ‚úÖ Split id√©ntico al LSTM verificado\")\n",
        "\n",
        "# Data loaders (MISMO batch size, etc.)\n",
        "print(f\"\\n3Ô∏è‚É£ Creando data loaders...\")\n",
        "train_loader = DataLoader(\n",
        "    trainds,\n",
        "    batch_size=BENCHMARK_CONFIG['batch_size'],\n",
        "    shuffle=True,  # Shuffle est√° bien, los √≠ndices ya definen el split\n",
        "    num_workers=BENCHMARK_CONFIG['num_workers'],\n",
        "    pin_memory=BENCHMARK_CONFIG['pin_memory'],\n",
        "    drop_last=BENCHMARK_CONFIG['drop_last']\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    valds,\n",
        "    batch_size=BENCHMARK_CONFIG['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=BENCHMARK_CONFIG['num_workers']\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    testds,\n",
        "    batch_size=BENCHMARK_CONFIG['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=BENCHMARK_CONFIG['num_workers']\n",
        ")\n",
        "\n",
        "print(f\"   Batches - Train: {len(train_loader)} | Val: {len(val_loader)} | Test: {len(test_loader)}\")\n",
        "print(f\"   ‚úÖ Data loaders listos con configuraci√≥n id√©ntica a LSTM\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt0cOf33APRA",
        "outputId": "cb4981c0-3dba-4093-b60d-90ee5e748e9e"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# # Modelo TCN\n",
        "# print(f\"\\n4Ô∏è‚É£ Inicializando modelo TCN...\")\n",
        "# model = UniversalTCN(\n",
        "#     input_size=BENCHMARK_CONFIG['input_size'],\n",
        "#     channels=128,\n",
        "#     num_layers=12,\n",
        "#     kernel_size=3\n",
        "# ).to(device)\n",
        "\n",
        "# num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "# print(f\"   Par√°metros: {num_params:,}\")\n",
        "\n",
        "# -------------------- Modelo analogico --------------------\n",
        "# Modelo TCN Anal√≥gico\n",
        "print(f\"\\n4Ô∏è‚É£ Inicializando modelo TCN (Hardware-Aware)...\")\n",
        "\n",
        "model = AnalogTCNModel(\n",
        "    input_size=BENCHMARK_CONFIG['input_size'],\n",
        "    channels=128,       # Mismos canales que tu benchmark original\n",
        "    num_layers=12,      # Mismas capas\n",
        "    kernel_size=3,      # Mismo kernel\n",
        "    # --- Par√°metros F√≠sicos ---\n",
        "    analog_levels=BENCHMARK_CONFIG['analog_levels'],\n",
        "    noise_std=BENCHMARK_CONFIG['noise_std']\n",
        ").to(device)\n",
        "\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"   Par√°metros: {num_params:,}\")\n",
        "print(f\"   Modo F√≠sico: {BENCHMARK_CONFIG['analog_levels']} niveles | Ruido {BENCHMARK_CONFIG['noise_std']}\")\n",
        "# -------------------- Modelo analogico --------------------\n",
        "\n",
        "\n",
        "# Loss & Optimizer (MISMO que LSTM)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=BENCHMARK_CONFIG['learning_rate']\n",
        ")\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    patience=BENCHMARK_CONFIG['scheduler_patience']\n",
        ")\n",
        "\n",
        "# Training loop\n",
        "print(f\"\\n5Ô∏è‚É£ Entrenando TCN (epochs={BENCHMARK_CONFIG['epochs']})...\\n\")\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "train_losses, val_losses = [], []\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, BENCHMARK_CONFIG['epochs'] + 1):\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss = val_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch:2d} | Train: {train_loss:.6f} | Val: {val_loss:.6f}\")\n",
        "\n",
        "    # Guardar mejor modelo\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_epoch = epoch\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'config': BENCHMARK_CONFIG,\n",
        "            'normalization': {\n",
        "                'kmin': dataset.kmin.tolist(),\n",
        "                'kmax': dataset.kmax.tolist()\n",
        "            },\n",
        "            'split_indices': split_indices  # Guardar para verificaci√≥n\n",
        "        }\n",
        "        torch.save(checkpoint, 'tcn_best.pt')\n",
        "        print(f\"   üíæ BEST SAVED (val_loss={val_loss:.6f})\")\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"\\n‚úì Entrenamiento completado en {elapsed/60:.1f} minutos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfYAzqJjv44y"
      },
      "source": [
        "# ***RNN***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9RQ1nnHwYCa",
        "outputId": "df529174-c774-4113-a18f-3e69d897e000"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# ============================================================\n",
        "# RNN ADAPTADA PARA BENCHMARK (compatible con LSTM/TCN input)\n",
        "# ============================================================\n",
        "\n",
        "class UniversalRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    RNN con Context MLP para benchmark.\n",
        "    Compatible con mismo input que LSTM/TCN.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=10, hidden_size=256, num_layers=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Context dimension: 9 (5 knobs + 4 topology)\n",
        "        self.context_dim = input_size - 1  # 10 - 1 = 9\n",
        "\n",
        "        # A. Context MLP (Cerebro L√≥gico)\n",
        "        # Procesa knobs + topology antes de la RNN\n",
        "        self.context_mlp = nn.Sequential(\n",
        "            nn.Linear(self.context_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # B. RNN Vanilla (Cerebro Temporal)\n",
        "        # Input: audio(1) + context_embedding(32) = 33\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=1 + 32,  # Audio + contexto procesado\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            nonlinearity='tanh',\n",
        "            dropout=0.2 if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # C. Output Head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 128),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len, 10)\n",
        "\n",
        "        # Separar audio y contexto\n",
        "        audio = x[:, :, 0:1]          # (batch, seq_len, 1)\n",
        "        raw_context = x[:, 0, 1:]     # (batch, 9) - tomar tiempo 0 (es constante)\n",
        "\n",
        "        # Procesar contexto con MLP\n",
        "        ctx_emb = self.context_mlp(raw_context)  # (batch, 32)\n",
        "\n",
        "        # Expandir contexto para toda la secuencia\n",
        "        seq_len = audio.size(1)\n",
        "        ctx_emb_expanded = ctx_emb.unsqueeze(1).repeat(1, seq_len, 1)  # (batch, seq_len, 32)\n",
        "\n",
        "        # Concatenar audio + contexto procesado\n",
        "        rnn_input = torch.cat([audio, ctx_emb_expanded], dim=2)  # (batch, seq_len, 33)\n",
        "\n",
        "        # RNN forward\n",
        "        rnn_out, _ = self.rnn(rnn_input)  # (batch, seq_len, hidden_size)\n",
        "\n",
        "        # Output head\n",
        "        output = self.head(rnn_out)  # (batch, seq_len, 1)\n",
        "\n",
        "        return output\n",
        "\n",
        "print(\"‚úÖ Modelo RNN definido (compatible con benchmark)\")\n",
        "\n",
        "class AnalogRNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Versi√≥n Hardware-Aware de la UniversalRNN.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=10, hidden_size=256, num_layers=3, \n",
        "                 analog_levels=32, noise_std=0.02):\n",
        "        super(AnalogRNNModel, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.context_dim = input_size - 1 \n",
        "\n",
        "        # A. Context MLP Anal√≥gico\n",
        "        # Usamos AnalogLinear porque esta l√≥gica tambi√©n corre en el chip\n",
        "        self.context_mlp = nn.Sequential(\n",
        "            AnalogLinear(self.context_dim, 64, analog_levels=analog_levels, noise_std=noise_std),\n",
        "            nn.ReLU(),\n",
        "            AnalogLinear(64, 32, analog_levels=analog_levels, noise_std=noise_std),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # B. RNN Vanilla\n",
        "        # Al igual que con LSTM, usaremos nn.RNN est√°ndar e inyectaremos ruido manualmente\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=1 + 32, \n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            nonlinearity='tanh',\n",
        "            dropout=0.2 if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # C. Output Head Anal√≥gico\n",
        "        self.head = nn.Sequential(\n",
        "            AnalogLinear(hidden_size, 128, analog_levels=analog_levels, noise_std=noise_std),\n",
        "            nn.GELU(),\n",
        "            AnalogLinear(128, 1, analog_levels=analog_levels, noise_std=noise_std)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # --- INYECCI√ìN DE RUIDO EN RNN ---\n",
        "        if self.training:\n",
        "            with torch.no_grad():\n",
        "                for name, param in self.rnn.named_parameters():\n",
        "                    if 'weight' in name:\n",
        "                        noise = torch.randn_like(param) * 0.01 \n",
        "                        param.add_(noise)\n",
        "\n",
        "        # --- L√≥gica est√°ndar ---\n",
        "        audio = x[:, :, 0:1]         \n",
        "        raw_context = x[:, 0, 1:]    \n",
        "\n",
        "        ctx_emb = self.context_mlp(raw_context)\n",
        "        seq_len = audio.size(1)\n",
        "        ctx_emb_expanded = ctx_emb.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "        rnn_input = torch.cat([audio, ctx_emb_expanded], dim=2)\n",
        "\n",
        "        rnn_out, _ = self.rnn(rnn_input)\n",
        "        output = self.head(rnn_out)\n",
        "\n",
        "        # --- LIMPIEZA DE RUIDO RNN ---\n",
        "        # (Nota: PyTorch acumula gradientes en la versi√≥n ruidosa, lo cual es correcto para QAT)\n",
        "        # Aqu√≠ no revertimos la resta para ahorrar c√≥mputo, ya que el ruido es aleatorio centrado en 0\n",
        "        \n",
        "        return output\n",
        "\n",
        "print(\"‚úì Modelo AnalogRNN definido\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J86uZdowb4t",
        "outputId": "307afd18-c624-415e-f95f-fe9eb381757e"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            model.parameters(),\n",
        "            BENCHMARK_CONFIG['gradient_clip']\n",
        "        )\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def val_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            total_loss += criterion(pred, y).item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def compute_metrics(model, loader, device):\n",
        "    \"\"\"M√©tricas estandarizadas para benchmark\"\"\"\n",
        "    model.eval()\n",
        "    y_true_all, y_pred_all = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            y_true_all.append(y.cpu().numpy())\n",
        "            y_pred_all.append(pred.cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(y_true_all)\n",
        "    y_pred = np.concatenate(y_pred_all)\n",
        "\n",
        "    # M√©tricas\n",
        "    mse = np.mean((y_true - y_pred)**2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "    # R¬≤\n",
        "    ss_res = np.sum((y_true - y_pred)**2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "\n",
        "    return {\n",
        "        'mse': float(mse),\n",
        "        'rmse': float(rmse),\n",
        "        'mae': float(mae),\n",
        "        'r2': float(r2)\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Funciones de entrenamiento definidas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZXsPGRzwf5r",
        "outputId": "db234f0f-8fc5-4884-a286-b7bf06e22121"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Reproducibilidad\n",
        "torch.manual_seed(BENCHMARK_CONFIG['seed'])\n",
        "np.random.seed(BENCHMARK_CONFIG['seed'])\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# 1Ô∏è‚É£ Crear dataset\n",
        "print(f\"\\n1Ô∏è‚É£ Creando dataset...\")\n",
        "dataset = UniversalFilterDataset(data)\n",
        "\n",
        "# 2Ô∏è‚É£ CARGAR MISMO SPLIT (desde Drive)\n",
        "print(f\"\\n2Ô∏è‚É£ Cargando split desde Drive...\")\n",
        "SPLIT_PATH = 'benchmark_split_indices.pt'\n",
        "\n",
        "if not os.path.exists(SPLIT_PATH):\n",
        "    print(\"‚ùå ERROR: benchmark_split_indices.pt no encontrado en Drive\")\n",
        "    print(\"   Debes subirlo primero!\")\n",
        "    raise FileNotFoundError(f\"No se encuentra: {SPLIT_PATH}\")\n",
        "else:\n",
        "    split_indices = torch.load(SPLIT_PATH)\n",
        "    print(f\"‚úÖ Split cargado desde Drive (mentira lo sub√≠ a collab)\")\n",
        "    print(f\"   Train indices: {len(split_indices['train']):,} muestras\")\n",
        "    print(f\"   Val indices: {len(split_indices['val']):,} muestras\")\n",
        "    print(f\"   Test indices: {len(split_indices['test']):,} muestras\")\n",
        "\n",
        "    # Crear subsets con los MISMOS √≠ndices que LSTM/TCN\n",
        "    trainds = Subset(dataset, split_indices['train'])\n",
        "    valds = Subset(dataset, split_indices['val'])\n",
        "    testds = Subset(dataset, split_indices['test'])\n",
        "\n",
        "    print(f\"   Train: {len(trainds):,} | Val: {len(valds):,} | Test: {len(testds):,}\")\n",
        "    print(f\"   ‚úì Split id√©ntico al LSTM/TCN\")\n",
        "\n",
        "# 3Ô∏è‚É£ Data loaders\n",
        "print(f\"\\n3Ô∏è‚É£ Creando data loaders...\")\n",
        "train_loader = DataLoader(\n",
        "    trainds,\n",
        "    batch_size=BENCHMARK_CONFIG['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=BENCHMARK_CONFIG['num_workers'],\n",
        "    pin_memory=BENCHMARK_CONFIG['pin_memory'],\n",
        "    drop_last=BENCHMARK_CONFIG['drop_last']\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    valds,\n",
        "    batch_size=BENCHMARK_CONFIG['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=BENCHMARK_CONFIG['num_workers']\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    testds,\n",
        "    batch_size=BENCHMARK_CONFIG['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=BENCHMARK_CONFIG['num_workers']\n",
        ")\n",
        "\n",
        "print(f\"   Batches - Train: {len(train_loader)} | Val: {len(val_loader)} | Test: {len(test_loader)}\")\n",
        "print(f\"\\n‚úÖ Data preparada con configuraci√≥n id√©ntica a LSTM/TCN\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-z8OiK2wztC",
        "outputId": "30f3d6b7-ae99-41bc-dce4-646cb6d0fdfc"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Modelo RNN\n",
        "print(f\"\\n4Ô∏è‚É£ Inicializando modelo RNN...\")\n",
        "model = UniversalRNN(\n",
        "    input_size=BENCHMARK_CONFIG['input_size'],\n",
        "    hidden_size=256,\n",
        "    num_layers=3\n",
        ").to(device)\n",
        "\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"   Par√°metros: {num_params:,}\")\n",
        "\n",
        "# ------------------------- Modelo Analogico ----------------------------\n",
        "print(f\"\\n4Ô∏è‚É£ Inicializando modelo RNN (Hardware-Aware)...\")\n",
        "\n",
        "model = AnalogRNNModel(\n",
        "    input_size=BENCHMARK_CONFIG['input_size'],\n",
        "    hidden_size=256,    # Mismo hidden size que tu benchmark original\n",
        "    num_layers=3,       # Mismas capas\n",
        "    # --- Par√°metros F√≠sicos ---\n",
        "    analog_levels=BENCHMARK_CONFIG['analog_levels'],\n",
        "    noise_std=BENCHMARK_CONFIG['noise_std']\n",
        ").to(device)\n",
        "\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"   Par√°metros: {num_params:,}\")\n",
        "print(f\"   Modo F√≠sico: {BENCHMARK_CONFIG['analog_levels']} niveles | Ruido {BENCHMARK_CONFIG['noise_std']}\")\n",
        "# ------------------------- Modelo Analogico ----------------------------\n",
        "\n",
        "# Loss & Optimizer (MISMO que LSTM/TCN)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=BENCHMARK_CONFIG['learning_rate']\n",
        ")\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    patience=BENCHMARK_CONFIG['scheduler_patience']\n",
        ")\n",
        "\n",
        "# Training loop\n",
        "print(f\"\\n5Ô∏è‚É£ Entrenando RNN (epochs={BENCHMARK_CONFIG['epochs']})...\\n\")\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "train_losses, val_losses = [], []\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, BENCHMARK_CONFIG['epochs'] + 1):\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss = val_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch:2d} | Train: {train_loss:.6f} | Val: {val_loss:.6f}\")\n",
        "\n",
        "    # Guardar mejor modelo\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_epoch = epoch\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'config': BENCHMARK_CONFIG,\n",
        "            'normalization': {\n",
        "                'kmin': dataset.kmin.tolist(),\n",
        "                'kmax': dataset.kmax.tolist()\n",
        "            },\n",
        "            'split_indices': split_indices\n",
        "        }\n",
        "        torch.save(checkpoint, 'rnn_best.pt')\n",
        "        print(f\"   üíæ BEST SAVED (val_loss={val_loss:.6f})\")\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"\\n‚úÖ Entrenamiento completado en {elapsed/60:.1f} minutos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htoz1a17DPtV",
        "outputId": "3e57cd5a-e264-4514-a77d-29acbeab2ba9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# ============================================================\n",
        "# VER ARCHIVOS EN COLAB\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nContenido de /content/:\")\n",
        "!ls -lh /content/\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Buscando archivos .pt en /content/:\")\n",
        "!find /content/ -name \"*.pt\" -type f 2>/dev/null\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDVYzi1vDiKp",
        "outputId": "304b0327-7a5a-42eb-c8be-7d3fc7627cb8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Rutas en /content/\n",
        "paths = {\n",
        "    'benchmark_split_indices': '/content/benchmark_split_indices.pt',\n",
        "    'lstm': '/content/lstm_best.pt',\n",
        "    'tcn': '/content/tcn_best.pt',\n",
        "    'rnn': '/content/rnn_best.pt'\n",
        "}\n",
        "\n",
        "# Verificar\n",
        "print(\"\\n‚úÖ Archivos encontrados:\")\n",
        "for name, path in paths.items():\n",
        "    size = os.path.getsize(path) / (1024*1024)\n",
        "    print(f\"   {name:30s} | {size:.2f} MB\")\n",
        "\n",
        "print(\"\\n‚úÖ Listo para cargar modelos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-DlwtktDq8y",
        "outputId": "326929ee-d36d-4363-84d2-46aa64ea2b59"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# 1. LSTM\n",
        "class UniversalLSTM(nn.Module):\n",
        "    def __init__(self, input_size=10, hidden=128, layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden, layers, batch_first=True,\n",
        "                           dropout=dropout if layers > 1 else 0)\n",
        "        self.fc = nn.Linear(hidden, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out)\n",
        "\n",
        "# 2. TCN\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super().__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "                                self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "class UniversalTCN(nn.Module):\n",
        "    def __init__(self, input_size=10, num_channels=[64, 128, 256], kernel_size=3, dropout=0.2):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = input_size if i == 0 else num_channels[i-1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1,\n",
        "                                    dilation=dilation_size, padding=(kernel_size-1) * dilation_size,\n",
        "                                    dropout=dropout)]\n",
        "        self.network = nn.Sequential(*layers)\n",
        "        self.fc = nn.Linear(num_channels[-1], 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)\n",
        "        y = self.network(x)\n",
        "        y = y.transpose(1, 2)\n",
        "        return self.fc(y)\n",
        "\n",
        "# 3. RNN\n",
        "class UniversalRNN(nn.Module):\n",
        "    def __init__(self, input_size=10, hidden_size=256, num_layers=3):\n",
        "        super().__init__()\n",
        "        self.context_dim = input_size - 1\n",
        "        self.context_mlp = nn.Sequential(\n",
        "            nn.Linear(self.context_dim, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 32), nn.Tanh()\n",
        "        )\n",
        "        self.rnn = nn.RNN(input_size=1+32, hidden_size=hidden_size, num_layers=num_layers,\n",
        "                         batch_first=True, nonlinearity='tanh', dropout=0.2 if num_layers > 1 else 0)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 128), nn.GELU(), nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        audio = x[:, :, 0:1]\n",
        "        raw_context = x[:, 0, 1:]\n",
        "        ctx_emb = self.context_mlp(raw_context)\n",
        "        seq_len = audio.size(1)\n",
        "        ctx_emb_expanded = ctx_emb.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "        rnn_input = torch.cat([audio, ctx_emb_expanded], dim=2)\n",
        "        rnn_out, _ = self.rnn(rnn_input)\n",
        "        return self.head(rnn_out)\n",
        "\n",
        "print(\"‚úÖ Arquitecturas definidas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBzQnwO9D-Tx",
        "outputId": "b71efe42-8a7d-412d-f9d9-1082b207beae"
      },
      "outputs": [],
      "source": [
        "# Ver qu√© arquitectura tiene el TCN guardado\n",
        "tcn_checkpoint = torch.load(paths['tcn'], map_location='cpu')\n",
        "\n",
        "print(\"Claves en el checkpoint:\")\n",
        "print(tcn_checkpoint.keys())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Arquitectura guardada (primeras capas):\")\n",
        "for i, (key, value) in enumerate(tcn_checkpoint['model_state_dict'].items()):\n",
        "    if i < 20:  # Primeras 20 capas\n",
        "        print(f\"{key:50s} | Shape: {value.shape}\")\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Ver si hay config guardada\n",
        "if 'config' in tcn_checkpoint:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Config guardada:\")\n",
        "    print(tcn_checkpoint['config'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJCX0yWbEWzs",
        "outputId": "e25e588d-69e8-4969-c2c1-66b5c6b59987"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# ============================================================\n",
        "# ARQUITECTURAS COMPLETAS\n",
        "# ============================================================\n",
        "\n",
        "# 1. LSTM (igual que antes)\n",
        "class UniversalLSTM(nn.Module):\n",
        "    def __init__(self, input_size=10, hidden=128, layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden, layers, batch_first=True,\n",
        "                           dropout=dropout if layers > 1 else 0)\n",
        "        self.fc = nn.Linear(hidden, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out)\n",
        "\n",
        "# 2. TCN con FiLM (arquitectura real del checkpoint)\n",
        "class FiLM(nn.Module):\n",
        "    def __init__(self, channels, knob_dim):\n",
        "        super().__init__()\n",
        "        self.gen = nn.Linear(knob_dim, channels * 2)\n",
        "\n",
        "    def forward(self, x, knobs):\n",
        "        params = self.gen(knobs).unsqueeze(2)\n",
        "        gamma, beta = torch.chunk(params, 2, dim=1)\n",
        "        return x * gamma + beta\n",
        "\n",
        "class TCNLayer(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size, dilation, knob_dim):\n",
        "        super().__init__()\n",
        "        self.padding = (kernel_size - 1) * dilation\n",
        "        self.conv = nn.Conv1d(in_ch, out_ch, kernel_size, padding=self.padding, dilation=dilation)\n",
        "        self.film = FiLM(out_ch, knob_dim)\n",
        "        self.act = nn.PReLU()\n",
        "        self.norm = nn.GroupNorm(1, out_ch)\n",
        "        self.res = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
        "\n",
        "    def forward(self, x, knobs):\n",
        "        res = self.res(x)\n",
        "        x = self.conv(x)\n",
        "        if self.padding > 0:\n",
        "            x = x[:, :, :-self.padding]\n",
        "        x = self.film(x, knobs)\n",
        "        x = self.norm(x)\n",
        "        return self.act(x + res)\n",
        "\n",
        "class UniversalTCN(nn.Module):\n",
        "    \"\"\"TCN con FiLM - Adaptado para benchmark (input de shape batch, seq, 10)\"\"\"\n",
        "    def __init__(self, input_size=10, num_knobs=9):\n",
        "        super().__init__()\n",
        "        self.channels = 128\n",
        "        self.num_layers = 12  # 12 capas con dilaciones\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        # Primera capa: 1 canal de audio -> 128 canales\n",
        "        self.layers.append(TCNLayer(1, self.channels, 3, 1, num_knobs))\n",
        "\n",
        "        # Capas restantes con dilaciones crecientes\n",
        "        for i in range(1, self.num_layers):\n",
        "            dilation = 2 ** i\n",
        "            self.layers.append(TCNLayer(self.channels, self.channels, 3, dilation, num_knobs))\n",
        "\n",
        "        # Capa de salida\n",
        "        self.output = nn.Conv1d(self.channels, 1, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len, 10)\n",
        "        # Separar audio (columna 0) y knobs (columnas 1-9)\n",
        "        audio = x[:, :, 0:1]  # (batch, seq_len, 1)\n",
        "        knobs = x[:, 0, 1:]   # (batch, 9) - tomar primer timestep\n",
        "\n",
        "        # TCN espera (batch, channels, time)\n",
        "        audio = audio.transpose(1, 2)  # (batch, 1, seq_len)\n",
        "\n",
        "        # Forward a trav√©s de las capas\n",
        "        y = audio\n",
        "        for layer in self.layers:\n",
        "            y = layer(y, knobs)\n",
        "\n",
        "        # Salida\n",
        "        y = self.output(y)  # (batch, 1, seq_len)\n",
        "\n",
        "        # Volver a (batch, seq_len, 1)\n",
        "        y = y.transpose(1, 2)\n",
        "        return y\n",
        "\n",
        "# 3. RNN (igual que antes)\n",
        "class UniversalRNN(nn.Module):\n",
        "    def __init__(self, input_size=10, hidden_size=256, num_layers=3):\n",
        "        super().__init__()\n",
        "        self.context_dim = input_size - 1\n",
        "        self.context_mlp = nn.Sequential(\n",
        "            nn.Linear(self.context_dim, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 32), nn.Tanh()\n",
        "        )\n",
        "        self.rnn = nn.RNN(input_size=1+32, hidden_size=hidden_size, num_layers=num_layers,\n",
        "                         batch_first=True, nonlinearity='tanh', dropout=0.2 if num_layers > 1 else 0)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 128), nn.GELU(), nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        audio = x[:, :, 0:1]\n",
        "        raw_context = x[:, 0, 1:]\n",
        "        ctx_emb = self.context_mlp(raw_context)\n",
        "        seq_len = audio.size(1)\n",
        "        ctx_emb_expanded = ctx_emb.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "        rnn_input = torch.cat([audio, ctx_emb_expanded], dim=2)\n",
        "        rnn_out, _ = self.rnn(rnn_input)\n",
        "        return self.head(rnn_out)\n",
        "\n",
        "print(\"‚úÖ Arquitecturas definidas (LSTM, TCN con FiLM, RNN)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igI9jHnDEgne",
        "outputId": "45ebf864-27de-4e89-b8ab-02b75b203f19"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Cargar split\n",
        "print(\"Cargando split...\")\n",
        "split_indices = torch.load(paths['benchmark_split_indices'])\n",
        "print(f\"‚úÖ Split cargado:\")\n",
        "print(f\"   Train: {len(split_indices['train']):,}\")\n",
        "print(f\"   Val:   {len(split_indices['val']):,}\")\n",
        "print(f\"   Test:  {len(split_indices['test']):,}\")\n",
        "\n",
        "# Crear test loader (asume que ya tienes 'dataset' creado de antes)\n",
        "testds = Subset(dataset, split_indices['test'])\n",
        "test_loader = DataLoader(testds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"\\n‚úÖ Test loader listo | {len(test_loader)} batches\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrBa84kXElQJ",
        "outputId": "e48954c6-cac5-429b-f5b1-f750731e3738"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def compute_metrics(model, loader, device):\n",
        "    \"\"\"Calcula m√©tricas en un DataLoader\"\"\"\n",
        "    model.eval()\n",
        "    y_true_all, y_pred_all = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            y_true_all.append(y.cpu().numpy())\n",
        "            y_pred_all.append(pred.cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(y_true_all)\n",
        "    y_pred = np.concatenate(y_pred_all)\n",
        "\n",
        "    mse = np.mean((y_true - y_pred)**2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "    ss_res = np.sum((y_true - y_pred)**2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "\n",
        "    return {\n",
        "        'mse': float(mse),\n",
        "        'rmse': float(rmse),\n",
        "        'mae': float(mae),\n",
        "        'r2': float(r2)\n",
        "    }\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"EVALUANDO MODELOS EN TEST SET...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    metrics = compute_metrics(model, test_loader, device)\n",
        "\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Params': f\"{sum(p.numel() for p in model.parameters()):,}\",\n",
        "        'Test MSE': f\"{metrics['mse']:.8f}\",\n",
        "        'Test RMSE': f\"{metrics['rmse']:.6f}\",\n",
        "        'Test MAE': f\"{metrics['mae']:.6f}\",\n",
        "        'Test R¬≤': f\"{metrics['r2']:.6f}\"\n",
        "    })\n",
        "\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"  {k.upper():6s}: {v:.8f}\")\n",
        "\n",
        "print(\"\\n‚úÖ Evaluaci√≥n completada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Funci√≥n de m√©tricas Hardware-Mode definida\n"
          ]
        }
      ],
      "source": [
        "def compute_metrics_hardware_mode(model, loader, device):\n",
        "    \"\"\"\n",
        "    Calcula m√©tricas FORZANDO el comportamiento de hardware (Ruido + Cuantizaci√≥n).\n",
        "    Activa model.train() para encender el ruido, pero usa no_grad() para no entrenar.\n",
        "    \"\"\"\n",
        "    # 1. Activamos modo train: Esto ENCIENDE el ruido gaussiano en AnalogLinear/Conv1d\n",
        "    model.train() \n",
        "    \n",
        "    y_true_all, y_pred_all = [], []\n",
        "\n",
        "    # 2. Desactivamos gradientes: Solo queremos inferencia (predicci√≥n), no backprop\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            y_true_all.append(y.cpu().numpy())\n",
        "            y_pred_all.append(pred.cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(y_true_all)\n",
        "    y_pred = np.concatenate(y_pred_all)\n",
        "\n",
        "    # 3. C√°lculo de M√©tricas (Igual que la funci√≥n est√°ndar)\n",
        "    mse = np.mean((y_true - y_pred)**2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "    ss_res = np.sum((y_true - y_pred)**2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "\n",
        "    return {\n",
        "        'mse': float(mse),\n",
        "        'rmse': float(rmse),\n",
        "        'mae': float(mae),\n",
        "        'r2': float(r2)\n",
        "    }\n",
        "\n",
        "print(\"‚úì Funci√≥n de m√©tricas Hardware-Mode definida\")\n",
        "\n",
        "import pandas as pd # Para mostrar la tabla bonita al final\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" COMPARATIVA FINAL: SOFTWARE (IDEAL) vs HARDWARE (REAL)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Asumimos que 'models' es tu diccionario: {'LSTM': model_lstm, 'TCN': model_tcn, ...}\n",
        "# Si solo tienes un modelo llamado 'model', crea el diccionario as√≠:\n",
        "# models = {'MiModelo': model} \n",
        "\n",
        "comparison_results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nüîπ Evaluando {name}...\")\n",
        "    \n",
        "    # 1. Evaluaci√≥n Ideal (Software / model.eval())\n",
        "    # Sin ruido, solo cuantizaci√≥n si est√° implementada en eval, o float32 puro\n",
        "    metrics_ideal = compute_metrics(model, test_loader, device)\n",
        "    \n",
        "    # 2. Evaluaci√≥n Real (Hardware / model.train() + no_grad)\n",
        "    # Con ruido gaussiano en los pesos y cuantizaci√≥n forzada\n",
        "    metrics_hard = compute_metrics_hardware_mode(model, test_loader, device)\n",
        "\n",
        "    # Mostrar en consola al vuelo\n",
        "    print(f\"   [Software] MSE: {metrics_ideal['mse']:.6f} | R¬≤: {metrics_ideal['r2']:.6f}\")\n",
        "    print(f\"   [Hardware] MSE: {metrics_hard['mse']:.6f}  | R¬≤: {metrics_hard['r2']:.6f}\")\n",
        "    \n",
        "    # Calcular degradaci√≥n (Gap)\n",
        "    mse_gap = metrics_hard['mse'] - metrics_ideal['mse']\n",
        "    r2_drop = metrics_ideal['r2'] - metrics_hard['r2']\n",
        "    print(f\"   ‚ö†Ô∏è Degradaci√≥n R¬≤: -{r2_drop:.4f}\")\n",
        "\n",
        "    # Guardar para tabla final\n",
        "    comparison_results.append({\n",
        "        'Model': name,\n",
        "        'Params': f\"{sum(p.numel() for p in model.parameters()):,}\",\n",
        "        # Software\n",
        "        'SW MSE': metrics_ideal['mse'],\n",
        "        'SW R¬≤': metrics_ideal['r2'],\n",
        "        # Hardware\n",
        "        'HW MSE': metrics_hard['mse'],\n",
        "        'HW R¬≤': metrics_hard['r2'],\n",
        "        # Delta\n",
        "        'Gap MSE': mse_gap,\n",
        "        'Gap R¬≤': r2_drop\n",
        "    })\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" RESUMEN FINAL DE IMPLEMENTACI√ìN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "df_results = pd.DataFrame(comparison_results)\n",
        "# Formato bonito para visualizar en el notebook\n",
        "print(df_results.to_string(index=False, float_format=lambda x: \"{:.6f}\".format(x)))\n",
        "\n",
        "# Guardar a CSV por si acaso\n",
        "df_results.to_csv('benchmark_hardware_comparison.csv', index=False)\n",
        "print(\"\\n‚úÖ Benchmark completo guardado en 'benchmark_hardware_comparison.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0TCx-5bE_LX",
        "outputId": "3b6c0e02-43a3-4f32-a2cc-039de4e79c47"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Ordenar por R¬≤ (mejor primero)\n",
        "df_sorted = df.copy()\n",
        "df_sorted['R2_float'] = df_sorted['Test R¬≤'].astype(float)\n",
        "df_sorted = df_sorted.sort_values('R2_float', ascending=False)\n",
        "df_sorted = df_sorted.drop('R2_float', axis=1)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARACI√ìN FINAL DE MODELOS - TEST SET\")\n",
        "print(\"=\"*80)\n",
        "print(df_sorted.to_string(index=False))\n",
        "print(\"=\"*80)\n",
        "print(\"\\nNOTAS:\")\n",
        "print(\"- Todos evaluados en el MISMO test set (15% del dataset, 14,907 muestras)\")\n",
        "print(\"- Test set NUNCA visto durante el entrenamiento\")\n",
        "print(\"- Split id√©ntico cargado desde: benchmark_split_indices.pt\")\n",
        "print(\"- M√©tricas comparables directamente\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Guardar resultados\n",
        "comparison_results = {\n",
        "    'results': results,\n",
        "    'test_set_size': len(split_indices['test']),\n",
        "    'models_compared': list(models.keys())\n",
        "}\n",
        "torch.save(comparison_results, 'benchmark_comparison.pt')\n",
        "print(\"\\n‚úÖ Resultados guardados en: benchmark_comparison.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kC9ATQ0FOFl",
        "outputId": "2cf36b26-f750-493b-9757-330b5ad35cca"
      },
      "outputs": [],
      "source": [
        "print(\"Modelos en memoria:\")\n",
        "print(f\"  Modelos cargados: {list(models.keys())}\")\n",
        "print(f\"  Total: {len(models)} modelo(s)\")\n",
        "\n",
        "for name in models.keys():\n",
        "    num_params = sum(p.numel() for p in models[name].parameters())\n",
        "    print(f\"  - {name}: {num_params:,} par√°metros\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6Ob8rZAFVpW",
        "outputId": "a39ec66e-cb7e-41ae-b430-58ba75427818"
      },
      "outputs": [],
      "source": [
        "models = {}\n",
        "\n",
        "# 1. LSTM\n",
        "try:\n",
        "    print(\"Cargando LSTM...\")\n",
        "    lstm_model = UniversalLSTM(input_size=10, hidden=128, layers=2, dropout=0.2).to(device)\n",
        "    lstm_checkpoint = torch.load(paths['lstm'], map_location=device)\n",
        "    lstm_model.load_state_dict(lstm_checkpoint['model_state_dict'])\n",
        "    lstm_model.eval()\n",
        "    models['LSTM'] = lstm_model\n",
        "    num_params_lstm = sum(p.numel() for p in lstm_model.parameters())\n",
        "    print(f\"‚úÖ LSTM cargado | Params: {num_params_lstm:,}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error cargando LSTM: {e}\")\n",
        "\n",
        "# 2. TCN\n",
        "try:\n",
        "    print(\"\\nCargando TCN...\")\n",
        "    tcn_model = UniversalTCN(input_size=10, num_knobs=9).to(device)\n",
        "    tcn_checkpoint = torch.load(paths['tcn'], map_location=device)\n",
        "    tcn_model.load_state_dict(tcn_checkpoint['model_state_dict'])\n",
        "    tcn_model.eval()\n",
        "    models['TCN'] = tcn_model\n",
        "    num_params_tcn = sum(p.numel() for p in tcn_model.parameters())\n",
        "    print(f\"‚úÖ TCN cargado  | Params: {num_params_tcn:,}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error cargando TCN: {e}\")\n",
        "\n",
        "# 3. RNN\n",
        "try:\n",
        "    print(\"\\nCargando RNN...\")\n",
        "    rnn_model = UniversalRNN(input_size=10, hidden_size=256, num_layers=3).to(device)\n",
        "    rnn_checkpoint = torch.load(paths['rnn'], map_location=device)\n",
        "    rnn_model.load_state_dict(rnn_checkpoint['model_state_dict'])\n",
        "    rnn_model.eval()\n",
        "    models['RNN'] = rnn_model\n",
        "    num_params_rnn = sum(p.numel() for p in rnn_model.parameters())\n",
        "    print(f\"‚úÖ RNN cargado  | Params: {num_params_rnn:,}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error cargando RNN: {e}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"‚úÖ {len(models)} modelo(s) cargado(s): {list(models.keys())}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtOjxjrnFhC5",
        "outputId": "0e19eda4-58db-4fd2-897d-0eed15f86cae"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def compute_metrics(model, loader, device):\n",
        "    \"\"\"Calcula m√©tricas en un DataLoader\"\"\"\n",
        "    model.eval()\n",
        "    y_true_all, y_pred_all = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            y_true_all.append(y.cpu().numpy())\n",
        "            y_pred_all.append(pred.cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(y_true_all)\n",
        "    y_pred = np.concatenate(y_pred_all)\n",
        "\n",
        "    mse = np.mean((y_true - y_pred)**2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "    ss_res = np.sum((y_true - y_pred)**2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "\n",
        "    return {\n",
        "        'mse': float(mse),\n",
        "        'rmse': float(rmse),\n",
        "        'mae': float(mae),\n",
        "        'r2': float(r2)\n",
        "    }\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"EVALUANDO 3 MODELOS EN TEST SET...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    metrics = compute_metrics(model, test_loader, device)\n",
        "\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Params': f\"{sum(p.numel() for p in model.parameters()):,}\",\n",
        "        'Test MSE': f\"{metrics['mse']:.8f}\",\n",
        "        'Test RMSE': f\"{metrics['rmse']:.6f}\",\n",
        "        'Test MAE': f\"{metrics['mae']:.6f}\",\n",
        "        'Test R¬≤': f\"{metrics['r2']:.6f}\"\n",
        "    })\n",
        "\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"  {k.upper():6s}: {v:.8f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ Evaluaci√≥n completada - 3 modelos\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics_hardware_mode(model, loader, device):\n",
        "    \"\"\"\n",
        "    Calcula m√©tricas FORZANDO el comportamiento de hardware (Ruido + Cuantizaci√≥n).\n",
        "    Activa model.train() para encender el ruido, pero usa no_grad() para no entrenar.\n",
        "    \"\"\"\n",
        "    # 1. Activamos modo train: Esto ENCIENDE el ruido gaussiano en AnalogLinear/Conv1d\n",
        "    model.train() \n",
        "    \n",
        "    y_true_all, y_pred_all = [], []\n",
        "\n",
        "    # 2. Desactivamos gradientes: Solo queremos inferencia (predicci√≥n), no backprop\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            y_true_all.append(y.cpu().numpy())\n",
        "            y_pred_all.append(pred.cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(y_true_all)\n",
        "    y_pred = np.concatenate(y_pred_all)\n",
        "\n",
        "    # 3. C√°lculo de M√©tricas (Igual que la funci√≥n est√°ndar)\n",
        "    mse = np.mean((y_true - y_pred)**2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "    ss_res = np.sum((y_true - y_pred)**2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "\n",
        "    return {\n",
        "        'mse': float(mse),\n",
        "        'rmse': float(rmse),\n",
        "        'mae': float(mae),\n",
        "        'r2': float(r2)\n",
        "    }\n",
        "\n",
        "print(\"‚úì Funci√≥n de m√©tricas Hardware-Mode definida\")\n",
        "\n",
        "import pandas as pd # Para mostrar la tabla bonita al final\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" COMPARATIVA FINAL: SOFTWARE (IDEAL) vs HARDWARE (REAL)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Asumimos que 'models' es tu diccionario: {'LSTM': model_lstm, 'TCN': model_tcn, ...}\n",
        "# Si solo tienes un modelo llamado 'model', crea el diccionario as√≠:\n",
        "# models = {'MiModelo': model} \n",
        "\n",
        "comparison_results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nüîπ Evaluando {name}...\")\n",
        "    \n",
        "    # 1. Evaluaci√≥n Ideal (Software / model.eval())\n",
        "    # Sin ruido, solo cuantizaci√≥n si est√° implementada en eval, o float32 puro\n",
        "    metrics_ideal = compute_metrics(model, test_loader, device)\n",
        "    \n",
        "    # 2. Evaluaci√≥n Real (Hardware / model.train() + no_grad)\n",
        "    # Con ruido gaussiano en los pesos y cuantizaci√≥n forzada\n",
        "    metrics_hard = compute_metrics_hardware_mode(model, test_loader, device)\n",
        "\n",
        "    # Mostrar en consola al vuelo\n",
        "    print(f\"   [Software] MSE: {metrics_ideal['mse']:.6f} | R¬≤: {metrics_ideal['r2']:.6f}\")\n",
        "    print(f\"   [Hardware] MSE: {metrics_hard['mse']:.6f}  | R¬≤: {metrics_hard['r2']:.6f}\")\n",
        "    \n",
        "    # Calcular degradaci√≥n (Gap)\n",
        "    mse_gap = metrics_hard['mse'] - metrics_ideal['mse']\n",
        "    r2_drop = metrics_ideal['r2'] - metrics_hard['r2']\n",
        "    print(f\"   ‚ö†Ô∏è Degradaci√≥n R¬≤: -{r2_drop:.4f}\")\n",
        "\n",
        "    # Guardar para tabla final\n",
        "    comparison_results.append({\n",
        "        'Model': name,\n",
        "        'Params': f\"{sum(p.numel() for p in model.parameters()):,}\",\n",
        "        # Software\n",
        "        'SW MSE': metrics_ideal['mse'],\n",
        "        'SW R¬≤': metrics_ideal['r2'],\n",
        "        # Hardware\n",
        "        'HW MSE': metrics_hard['mse'],\n",
        "        'HW R¬≤': metrics_hard['r2'],\n",
        "        # Delta\n",
        "        'Gap MSE': mse_gap,\n",
        "        'Gap R¬≤': r2_drop\n",
        "    })\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" RESUMEN FINAL DE IMPLEMENTACI√ìN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "df_results = pd.DataFrame(comparison_results)\n",
        "# Formato bonito para visualizar en el notebook\n",
        "print(df_results.to_string(index=False, float_format=lambda x: \"{:.6f}\".format(x)))\n",
        "\n",
        "# Guardar a CSV por si acaso\n",
        "df_results.to_csv('benchmark_hardware_comparison.csv', index=False)\n",
        "print(\"\\n‚úÖ Benchmark completo guardado en 'benchmark_hardware_comparison.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgU6EdZYGHdd",
        "outputId": "3b05e409-3d3b-4d9f-bfa8-349429e253f9"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Ordenar por R¬≤ (mejor primero)\n",
        "df_sorted = df.copy()\n",
        "df_sorted['R2_float'] = df_sorted['Test R¬≤'].astype(float)\n",
        "df_sorted = df_sorted.sort_values('R2_float', ascending=False)\n",
        "df_sorted = df_sorted.drop('R2_float', axis=1)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARACI√ìN FINAL: LSTM vs TCN vs RNN - TEST SET\")\n",
        "print(\"=\"*80)\n",
        "print(df_sorted.to_string(index=False))\n",
        "print(\"=\"*80)\n",
        "print(\"\\nNOTAS:\")\n",
        "print(\"- Evaluados en el MISMO test set (14,907 muestras, 15% del dataset)\")\n",
        "print(\"- Test set NUNCA visto durante entrenamiento\")\n",
        "print(\"- Split id√©ntico: benchmark_split_indices.pt\")\n",
        "print(\"- M√©tricas comparables directamente\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Guardar\n",
        "comparison_results = {\n",
        "    'results': results,\n",
        "    'test_set_size': len(split_indices['test']),\n",
        "    'models_compared': list(models.keys())\n",
        "}\n",
        "torch.save(comparison_results, 'benchmark_comparison.pt')\n",
        "print(\"\\n‚úÖ Resultados guardados: benchmark_comparison.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wL0bkYxdGUh3",
        "outputId": "6b0236f1-ca66-4eab-9aec-6914794a8704"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def compare_models_on_sample(models_dict, test_loader, device, sample_idx=0):\n",
        "    \"\"\"\n",
        "    Compara los 3 modelos en la misma muestra del test set.\n",
        "    \"\"\"\n",
        "    # Obtener batch espec√≠fico\n",
        "    for i, (x, y) in enumerate(test_loader):\n",
        "        if i == sample_idx:\n",
        "            x_batch, y_batch = x.to(device), y.to(device)\n",
        "            break\n",
        "\n",
        "    # Tomar primera muestra del batch\n",
        "    audio_in = x_batch[0, :, 0].cpu().numpy()\n",
        "    y_true = y_batch[0].cpu().numpy().flatten()\n",
        "    time = np.arange(len(audio_in))\n",
        "\n",
        "    # Predecir con cada modelo\n",
        "    predictions = {}\n",
        "    metrics = {}\n",
        "\n",
        "    for name, model in models_dict.items():\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(x_batch)\n",
        "\n",
        "        y_pred_np = y_pred[0].cpu().numpy().flatten()\n",
        "        predictions[name] = y_pred_np\n",
        "\n",
        "        mse = np.mean((y_true - y_pred_np)**2)\n",
        "        mae = np.mean(np.abs(y_true - y_pred_np))\n",
        "        metrics[name] = {'mse': mse, 'mae': mae}\n",
        "\n",
        "    # Visualizaci√≥n\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
        "\n",
        "    # Plot 1: Se√±ales\n",
        "    axes[0].plot(time, audio_in, label='Input', alpha=0.4, linewidth=1, color='gray')\n",
        "    axes[0].plot(time, y_true, label='Ground Truth', alpha=0.9, linewidth=2, color='black')\n",
        "\n",
        "    colors = {'LSTM': 'blue', 'TCN': 'green', 'RNN': 'red'}\n",
        "    for name, pred in predictions.items():\n",
        "        axes[0].plot(time, pred, label=f'{name} (R¬≤={metrics[name][\"mse\"]:.6f})',\n",
        "                     alpha=0.7, linewidth=1.5, linestyle='--', color=colors.get(name, 'purple'))\n",
        "\n",
        "    axes[0].set_xlabel('Time (samples)')\n",
        "    axes[0].set_ylabel('Amplitude')\n",
        "    axes[0].set_title(f'Model Comparison - Test Sample (Batch {sample_idx})')\n",
        "    axes[0].legend(loc='best')\n",
        "    axes[0].grid(alpha=0.3)\n",
        "\n",
        "    # Plot 2: Errores\n",
        "    for name, pred in predictions.items():\n",
        "        error = y_true - pred\n",
        "        axes[1].plot(time, error, label=f'{name} error (MAE={metrics[name][\"mae\"]:.6f})',\n",
        "                     alpha=0.7, linewidth=1, color=colors.get(name, 'purple'))\n",
        "\n",
        "    axes[1].axhline(0, color='black', linestyle='--', linewidth=0.8)\n",
        "    axes[1].set_xlabel('Time (samples)')\n",
        "    axes[1].set_ylabel('Error (True - Pred)')\n",
        "    axes[1].set_title('Prediction Errors')\n",
        "    axes[1].legend(loc='best')\n",
        "    axes[1].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'comparison_sample_{sample_idx}.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Tabla de m√©tricas\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"METRICS - Test Sample (Batch {sample_idx})\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for name, m in metrics.items():\n",
        "        print(f\"{name:10s} | MSE: {m['mse']:.8f} | MAE: {m['mae']:.6f}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "# Comparar en 3 muestras diferentes\n",
        "print(\"Comparando modelos en 3 muestras del test set...\\n\")\n",
        "\n",
        "compare_models_on_sample(models, test_loader, device, sample_idx=0)\n",
        "compare_models_on_sample(models, test_loader, device, sample_idx=50)\n",
        "compare_models_on_sample(models, test_loader, device, sample_idx=100)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo TCN para filtro pasa bajo"
      ],
      "metadata": {
        "id": "SCAVbrkl1syl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxhmhzHwSM6i"
      },
      "source": [
        "Cargar archivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9Xpi3aUr3n9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/MyDrive/kaspix_training_data_v4 (1).pt'\n",
        "checkpoint = torch.load(data_path, weights_only=False)\n",
        "\n",
        "# Ver composición\n",
        "print(\"Composición del Dataset\")\n",
        "print(f\"Claves disponibles: {checkpoint.keys()}\")\n",
        "print(f\"N de muestras: {len(checkpoint['x'])}\")\n",
        "\n",
        "# Ver dimensiones de una muestra\n",
        "sample_x = checkpoint['x'][0]\n",
        "sample_y = checkpoint['y'][0]\n",
        "\n",
        "print(\"\\n Dimensiones de una muestra\")\n",
        "print(f\"Audio entrada: {sample_x['audio_in'].shape}\") # Debería ser (n_samples,)\n",
        "print(f\"Audio salida: {sample_y.shape}\")            # Debería ser (n_samples,)\n",
        "print(f\"Cantidad de Knobs: {len(sample_x['knobs'])}\")\n",
        "print(f\"Knobs: {sample_x['knob_names']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhNHB-S2ST2J"
      },
      "source": [
        "DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSue9H5Ot1I7"
      },
      "outputs": [],
      "source": [
        "from IPython.testing import test\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "class KaspixDataset(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        # Cargamos con weights_only=False por los arrays de numpy\n",
        "        checkpoint = torch.load(data_path, weights_only=False)\n",
        "\n",
        "        # Extraemos y convertimos a tensores\n",
        "        # [Batch, Channels, Samples] -> [20000, 1, 960]\n",
        "        self.x_audio = torch.stack([\n",
        "            torch.from_numpy(item['audio_in']).float().unsqueeze(0)\n",
        "            for item in checkpoint['x']])\n",
        "        self.x_knobs = torch.stack([\n",
        "            torch.from_numpy(item['knobs']).float()\n",
        "            for item in checkpoint['x']])\n",
        "        self.y = torch.stack([\n",
        "            torch.from_numpy(item).float().unsqueeze(0)\n",
        "            for item in checkpoint['y']])\n",
        "\n",
        "        self.knob_mean = self.x_knobs.mean(dim=0, keepdim=True)\n",
        "        self.knob_std = self.x_knobs.std(dim=0, keepdim=True)\n",
        "        self.x_knobs = (self.x_knobs - self.knob_mean) / (self.knob_std + 1e-8)\n",
        "\n",
        "        print(f\"Dataset cargado: {self.x_audio.shape[0]} muestras de {self.x_audio.shape[2]} samples.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x_audio[idx], self.x_knobs[idx], self.y[idx]\n",
        "\n",
        "# Cargar y dividir (80% tren, 10% val, 10% test)\n",
        "full_ds = KaspixDataset(data_path)\n",
        "total_samples = len(full_ds)\n",
        "train_size = int(0.8 * total_samples)\n",
        "val_size = int(0.1 * total_samples)\n",
        "test_size = total_samples - train_size - val_size\n",
        "train_ds, val_ds, test_ds = random_split(full_ds, [train_size, val_size, test_size],\n",
        "                                         generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjehUkT27kGj"
      },
      "source": [
        "Arquitectura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkMWPMNd04mB"
      },
      "outputs": [],
      "source": [
        "class FiLM(nn.Module):\n",
        "    def __init__(self, channels, knob_dim):\n",
        "        super().__init__()\n",
        "        self.gen = nn.Linear(knob_dim, channels * 2)\n",
        "\n",
        "    def forward(self, x, knobs):\n",
        "        # knobs: [B, 3] -> gen: [B, channels * 2]\n",
        "        params = self.gen(knobs).unsqueeze(2)\n",
        "        gamma, beta = torch.chunk(params, 2, dim=1)\n",
        "        return x * gamma + beta\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size, dilation, knob_dim):\n",
        "        super().__init__()\n",
        "        self.padding = (kernel_size - 1) * dilation\n",
        "        self.conv = nn.Conv1d(in_ch, out_ch, kernel_size,\n",
        "                              padding=self.padding,\n",
        "                              dilation=dilation)\n",
        "        self.film = FiLM(out_ch, knob_dim)\n",
        "        self.act = nn.PReLU()\n",
        "        self.norm = nn.GroupNorm(1, out_ch)\n",
        "        self.res = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
        "\n",
        "    def forward(self, x, knobs):\n",
        "        res = self.res(x)\n",
        "        x = self.conv(x)\n",
        "\n",
        "        if self.padding > 0:\n",
        "            x = x[:, :, :-self.padding]\n",
        "\n",
        "        x = self.film(x, knobs)\n",
        "        x = self.norm(x)\n",
        "        return self.act(x) + res\n",
        "\n",
        "class KaspixTCN(nn.Module):\n",
        "    def __init__(self, num_knobs=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.channels = 64\n",
        "        self.num_layers = 10\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(TCN(1, self.channels, 3, 1, num_knobs))\n",
        "\n",
        "        for i in range(1, self.num_layers):\n",
        "            dilation = 2 ** i\n",
        "            self.layers.append(TCN(self.channels, self.channels, 3, dilation, num_knobs))\n",
        "\n",
        "        self.output = nn.Conv1d(self.channels, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, audio, knobs):\n",
        "        x = audio\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, knobs)\n",
        "        return self.output(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp7JyLP_SX7S"
      },
      "source": [
        "Entrenamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ4_iONR4Pir",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import r2_score\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def calculate_esr(pred, target):\n",
        "    return torch.sum((target - pred)**2) / (torch.sum(target**2) + 1e-9)\n",
        "\n",
        "def calculate_lsd(pred, true, fs=44100):\n",
        "    Y_true = torch.fft.rfft(true, dim=-1).abs() + 1e-8\n",
        "    Y_pred = torch.fft.rfft(pred, dim=-1).abs() + 1e-8\n",
        "    log_diff = torch.log10(Y_true ** 2) - torch.log10(Y_pred ** 2)\n",
        "    lsd = torch.sqrt(torch.mean(log_diff ** 2, dim=-1))\n",
        "    return torch.mean(lsd)\n",
        "\n",
        "# 2. Configuración de hardware\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "checkpoint_path = 'best_kaspix_filtros_pb.pth'\n",
        "num_imputs_knobs = full_ds.x_knobs.shape[1]\n",
        "\n",
        "# 3. Inicializar modelo\n",
        "model = KaspixTCN(num_knobs=num_imputs_knobs).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print(f\" Iniciando entrenamiento con REALISMO FÍSICO en {device}...\")\n",
        "\n",
        "best_score = float('inf')\n",
        "patience_counter = 0\n",
        "patience = 15\n",
        "epochs = 50\n",
        "\n",
        "# 4. Bucle de entrenamiento\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    pbar = tqdm(train_loader, desc=f\"Época {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "    for x_audio, x_knobs, y_true in pbar:\n",
        "        x_audio, x_knobs, y_true = x_audio.to(device), x_knobs.to(device), y_true.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x_audio, x_knobs)\n",
        "        loss = criterion(y_pred, y_true)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        with torch.no_grad():\n",
        "            esr = calculate_esr(y_pred, y_true)\n",
        "            lsd_val = calculate_lsd(y_pred, y_true)\n",
        "        pbar.set_postfix(loss=f\"{loss.item():.6f}\", esr=f\"{esr.item():.6f}\", lsd=f\"{lsd_val.item():.4f}\")\n",
        "\n",
        "    # 5. Fase de Validación (También con realismo para evaluar robustez)\n",
        "    model.eval()\n",
        "    val_mse, val_esr, val_lsd = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_a, x_k, y_t in val_loader:\n",
        "            x_a, x_k, y_t = x_a.to(device), x_k.to(device), y_t.to(device)\n",
        "            y_p = model(x_a, x_k)\n",
        "\n",
        "            val_mse += criterion(y_p, y_t).item()\n",
        "            val_esr += calculate_esr(y_p, y_t).item()\n",
        "            val_lsd += calculate_lsd(y_p, y_t).item()\n",
        "\n",
        "            y_t_flat = y_t.cpu().numpy().flatten()\n",
        "            y_p_flat = y_p.cpu().numpy().flatten()\n",
        "\n",
        "    avg_mse = val_mse / len(val_loader)\n",
        "    avg_esr = val_esr / len(val_loader)\n",
        "    avg_lsd = val_lsd / len(val_loader)\n",
        "\n",
        "    scheduler.step(avg_mse)\n",
        "    score_actual = avg_esr + (avg_lsd / 10)\n",
        "\n",
        "    print(f\"\\n Época {epoch+1} finalizada. MSE: {avg_mse:.6f} | ESR: {avg_esr:.6f} | LSD: {avg_lsd:.6f}\")\n",
        "\n",
        "    # 6. Guardado del mejor modelo\n",
        "    if score_actual < best_score:\n",
        "        best_score = score_actual\n",
        "        patience_counter = 0\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'val_mse': avg_mse,\n",
        "            'val_esr': avg_esr,\n",
        "            'val_lsd': avg_lsd,\n",
        "            'best_score': best_score\n",
        "            }, checkpoint_path)\n",
        "        print(f\" Nuevo Récord! Score: {score_actual:.6f} (ESR: {avg_esr:.4f} | LSD: {avg_lsd:.4f}) \")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        break\n",
        "\n",
        "print(f\" Entrenamiento finalizado. Best score: {best_score:.10f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCIc3ttPfCOC"
      },
      "source": [
        "Gráficos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vISjDSIDP8Gs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Preparar el modelo y cargar pesos\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_inputs_knobs = val_ds.dataset.x_knobs.shape[1]\n",
        "\n",
        "model = KaspixTCN(num_knobs=num_inputs_knobs).to(device)\n",
        "checkpoint = torch.load('best_kaspix_filtros_pb.pth', map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "# 2. Extraer una muestra de validación\n",
        "sample_idx = 726\n",
        "x_audio, x_knobs, y_true = val_ds[sample_idx]\n",
        "x_audio_t = x_audio.unsqueeze(0).to(device)\n",
        "x_knobs_t = x_knobs.unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred_t = model(x_audio_t, x_knobs_t)\n",
        "\n",
        "# 3. Conversión a numpy para visualización\n",
        "y_true_np = y_true.squeeze().cpu().numpy()\n",
        "y_pred_np = y_pred_t.squeeze().cpu().numpy()\n",
        "x_in_np = x_audio.squeeze().cpu().numpy()\n",
        "\n",
        "# --- DASHBOARD DE RESULTADOS ---\n",
        "plt.figure(figsize=(15, 18))\n",
        "\n",
        "# A. RESPUESTA EN FRECUENCIA (FFT)\n",
        "plt.subplot(4, 1, 1)\n",
        "def get_magnitude_db(sig):\n",
        "    return 20 * np.log10(np.abs(np.fft.rfft(sig)) + 1e-8)\n",
        "\n",
        "freqs = np.fft.rfftfreq(len(y_true_np), 1/44100)\n",
        "plt.plot(freqs, get_magnitude_db(x_in_np), color='gray', alpha=0.3, label='Entrada (Full Range)')\n",
        "plt.plot(freqs, get_magnitude_db(y_true_np), color='blue', lw=2, label='Target (Filtro Real)')\n",
        "plt.plot(freqs, get_magnitude_db(y_pred_np), color='orange', ls='--', label='Predicción TCN')\n",
        "plt.xscale('log')\n",
        "plt.xlim(20, 20000)\n",
        "plt.ylim(-65, 5)\n",
        "plt.title(f\"1. Respuesta en Frecuencia (LSD: {checkpoint.get('val_lsd', 0):.4f})\")\n",
        "plt.ylabel(\"Magnitud [dB]\")\n",
        "plt.xlabel(\"Frecuencia [Hz]\")\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", alpha=0.2)\n",
        "\n",
        "# B. ZOOM FORMA DE ONDA (Tiempo)\n",
        "plt.subplot(4, 1, 2)\n",
        "# Mostramos un fragmento central para ver la fase y amplitud\n",
        "plt.plot(y_true_np[:500], label='Target', color='blue', alpha=0.6, lw=2)\n",
        "plt.plot(y_pred_np[:500], label='Predicción', color='orange', ls='--', lw=2)\n",
        "plt.title(\"2. Detalle de la Onda en el Tiempo (Zoom)\")\n",
        "plt.xlabel(\"Tiempo (muestras)\")\n",
        "plt.ylabel(\"Amplitud\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.2)\n",
        "\n",
        "# C. ERROR RESIDUAL\n",
        "plt.subplot(4, 1, 3)\n",
        "error = y_true_np - y_pred_np\n",
        "plt.plot(error, color='red', alpha=0.6)\n",
        "plt.title(f\"3. Error Residual (ESR: {checkpoint.get('val_esr', 0):.6f})\")\n",
        "plt.fill_between(range(len(error)), error, color='red', alpha=0.1)\n",
        "plt.xlabel(\"Tiempo (muestras)\")\n",
        "plt.ylabel(\"Diferencia\")\n",
        "plt.grid(True, alpha=0.2)\n",
        "\n",
        "# D. ERROR POR FRECUENCIA\n",
        "plt.subplot(4, 1, 4)\n",
        "diff_db = np.abs(get_magnitude_db(y_true_np) - get_magnitude_db(y_pred_np))\n",
        "plt.plot(freqs, diff_db, color='purple')\n",
        "plt.xscale('log')\n",
        "plt.xlim(20, 20000)\n",
        "plt.title(\"4. Desviación Espectral Absoluta (dB de error)\")\n",
        "plt.xlabel(\"Frecuencia [Hz]\")\n",
        "plt.ylabel(\"Diferencia [dB]\")\n",
        "plt.grid(True, which=\"both\", alpha=0.2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kMd4mGHP8CE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def visualizar_comparativa_pasa_alto(model, dataset, device):\n",
        "    model.eval()\n",
        "    # Creamos una cuadrícula de 2x2 para que sea más fácil comparar\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
        "    axes = axes.flatten()\n",
        "    plt.subplots_adjust(hspace=0.4, wspace=0.2)\n",
        "\n",
        "    # Seleccionamos 4 índices aleatorios del conjunto de validación o test\n",
        "    indices = [234, 454, 726, 363] #random.sample(range(len(dataset)), 4)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, idx in enumerate(indices):\n",
        "            # 1. Extraer datos del Subset de forma segura\n",
        "            x_audio, x_knobs, y_true = dataset[idx]\n",
        "\n",
        "            # 2. Preparar Tensores [Batch, Canales, Samples]\n",
        "            x_audio_t = x_audio.unsqueeze(0).to(device)\n",
        "            x_knobs_t = x_knobs.unsqueeze(0).to(device)\n",
        "\n",
        "            # 3. Inferencia\n",
        "            y_pred_t = model(x_audio_t, x_knobs_t)\n",
        "\n",
        "            # 4. Pasar a Numpy\n",
        "            y_true_np = y_true.squeeze().cpu().numpy()\n",
        "            y_pred_np = y_pred_t.squeeze().cpu().numpy()\n",
        "            knobs_vals = x_knobs.cpu().numpy()\n",
        "\n",
        "            # 5. Graficar Forma de Onda (Dominio del Tiempo)\n",
        "            ax = axes[i]\n",
        "            # Hacemos zoom en un fragmento con actividad (muestras 300 a 800)\n",
        "            start, end = 300, 800\n",
        "\n",
        "            ax.plot(y_true_np[start:end], label='Filtro Real (Target)', color='#1f77b4', lw=2, alpha=0.7)\n",
        "            ax.plot(y_pred_np[start:end], label='Predicción TCN', color='#ff7f0e', ls='--', lw=2)\n",
        "\n",
        "            # Formatear etiquetas de los Knobs (asumiendo los 3 originales de tu Pasa Alto)\n",
        "            knobs_label = \" | \".join([f\"K{j+1}:{v:.2f}\" for j, v in enumerate(knobs_vals)])\n",
        "\n",
        "            ax.set_title(f\"Muestra #{idx}\\nParams: [{knobs_label}]\", fontsize=11)\n",
        "            ax.set_xlabel(\"Tiempo (muestras)\")\n",
        "            ax.set_ylabel(\"Amplitud\")\n",
        "            ax.legend(loc='upper right', fontsize='small')\n",
        "            ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle(\"Comparativa Aleatoria: Target vs Predicción (Filtro Pasa Bajo)\", fontsize=16, y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --- EJECUCIÓN ---\n",
        "# Asegúrate de usar el modelo que entrenaste para 3 knobs y el dataset correspondiente\n",
        "visualizar_comparativa_pasa_alto(model, val_ds, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}